{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional neural networks are not well designed to model the uncertainty associated with the predictions they make. For that, one way is to go full Bayesian. \n",
    "\n",
    "In this class we will introduce the concept of Bayesian Neural Networks (BNN) by studing a standard supervised use case: a toy regression problem. For that, we will first implement linear regression and learn point estimates for the parameters w and b. Then we’ll see how to incorporate uncertainty into our estimates by using MCMC to implement Bayesian linear regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayesian neural network is a neural network with a prior distribution on its weights. This means that, in contrast with any convential (non-Bayesian) neural network, BNNs are interested not only in the optimal values of the network's parameters -- weights and biases -- but also in the distribution associated with them. Thanks to these distributions we could have a certain level of confidence about the network predictions.\n",
    "\n",
    "The  idea  behind  Bayesian  neural  networks is then to cast the task of training a network as a problem of inference, which is solved using Bayes’ theorem. The latter theorem is used to assign a probability density to each point in the parameter space of the neural network, as it is featured below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Formula\n",
    "\n",
    "Estimating the distributions associated with the network parameters is hard. These are generally referred to as posterior densities, and are estimated using the Bayes rule.\n",
    "\n",
    "$$p \\left(w \\mid x,y \\right) = \\frac{p \\left( x,y \\mid w \\right) p(w)}{\\int p \\left( x, y \\mid w\\right) p(w)dw}$$\n",
    "\n",
    "The main problem lies in the denominator — also known as model evidence. It requires integrating over all possible values of the parameters (i.e., all weights and biases space), and it is often not doable in practice.\n",
    "\n",
    "Instead, pseudo-numerical approaches can be chosen where the solution to those integrals is approximated. The most common approaches are: \n",
    "\n",
    "1.- Approximating the integral with MCMC\n",
    "\n",
    "2.- Using variational inference \n",
    "\n",
    "3.-Using MC dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this notebook we will explore the MCMC approach with the help of the tensorflow_probability library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, let's dive deep into the basic principles with the regression example.\n",
    "\n",
    "Regression is one of the most common and basic supervised learning tasks in machine learning.\n",
    "\n",
    "Considering $\\mathcal{D} = \\left( \\boldsymbol{X},\\boldsymbol{Y} \\right) = \\left\\{ (\\boldsymbol{x}_i,y_i) \\right\\}_{i=1}^{N}$. Suppose there exist $f(x)$ so that \n",
    "\n",
    "$$y = f(x)$$\n",
    "\n",
    "We want to find $f(x) = \\phi_w (x)$ where $w$ are the parameters of the later function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first implement linear regression and learn point estimates for the parameters w and b. Then we’ll see how to incorporate uncertainty into our estimates to implement Bayesian linear regression.\n",
    "\n",
    "But, first of all, let’s import the modules we’ll need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.topology import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a toy dataset of 100 data points with one feature and w=3.5 and b=-9.3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "points = 100\n",
    "low = -1.\n",
    "high = 1.\n",
    "x_train = np.random.uniform(high = high, low=low, size=points)\n",
    "\n",
    "def f(x, w=3.5, b=-9.3):\n",
    "    return b + x*w\n",
    "\n",
    "y_train = f(x_train)\n",
    "\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add some constant noise in the predicted dimension:\n",
    "\n",
    "$$y = f(x) + \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "std = 0.4\n",
    "epsilon = np.random.normal(0,std, size = points)\n",
    "\n",
    "y_train = f(x_train) + epsilon\n",
    "\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.58992816e-01, -2.05332679e-02,  2.52477479e-02, -2.25373472e-02,\n",
       "        1.35138799e-01, -1.76526989e-01, -2.53217837e-01,  2.46789812e-01,\n",
       "       -1.29475134e-01,  5.34933631e-01, -6.19280708e-02,  3.28918025e-01,\n",
       "       -2.34217088e-01,  5.00890896e-01, -4.48424932e-01,  2.42033689e-01,\n",
       "        3.72850922e-01, -2.18290138e-01, -8.37850542e-01,  1.63226480e-02,\n",
       "       -2.66836789e-01, -1.11185810e-01, -1.85373815e-01,  7.45909941e-04,\n",
       "       -8.26484475e-03, -2.11534864e-01, -1.38674991e-02,  2.55752269e-01,\n",
       "        2.18271525e-01,  1.47436838e-01,  9.27083571e-02,  3.36886324e-01,\n",
       "       -3.85662617e-01, -6.25633883e-01, -6.25314996e-03,  5.25309738e-01,\n",
       "        3.32792850e-01,  7.15463893e-01, -1.42742713e-02,  6.23333815e-01,\n",
       "        2.11119177e-01, -3.80071764e-01,  1.77728084e-01, -1.42880302e-01,\n",
       "       -4.19089288e-01,  8.85673183e-01,  5.98441929e-01,  5.18244421e-01,\n",
       "        1.30913065e-01, -7.23267354e-02,  2.12422334e-01,  7.22648787e-01,\n",
       "        1.52597412e-01,  1.55509434e-01,  1.02735980e-01, -2.68521562e-01,\n",
       "        2.39624036e-02, -1.87609216e-01,  9.78798770e-02, -5.63486340e-01,\n",
       "        9.42242476e-02,  3.63293823e-01,  1.65315476e-01, -3.86059285e-01,\n",
       "       -5.09416519e-01, -7.72825318e-01, -3.71803059e-01,  2.78127557e-01,\n",
       "        3.89280188e-02,  6.76560666e-01, -4.74873918e-01,  6.42415563e-01,\n",
       "       -3.81868500e-01,  3.99802558e-01, -9.07548514e-02,  1.78664049e-01,\n",
       "       -7.03324695e-02,  3.28940985e-01, -1.86280984e-01, -7.55233638e-02,\n",
       "       -5.30749261e-01, -7.68856219e-02, -5.11204665e-01, -3.81203029e-02,\n",
       "        8.71268543e-01,  7.15302624e-01,  1.94948479e-02,  3.92297308e-01,\n",
       "        2.43299375e-01,  3.11069162e-01, -3.39344782e-01, -4.42289542e-01,\n",
       "       -3.96972139e-01,  6.17013224e-01, -1.77174956e-01,  4.31069749e-01,\n",
       "       -5.31431138e-01, -6.09667956e-01,  2.40307996e-01,  4.53648172e-01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the problem state as $$y = \\phi_w (x) + \\epsilon$$\n",
    "\n",
    "$$ p(y \\mid x, w, \\epsilon) = \\mathcal{N}(y \\mid \\phi_w(x), \\epsilon^2)$$\n",
    "\n",
    "where $\\phi_w (x) = w_1 x + w_2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(y_{i}\\mid x_{i},w, \\epsilon)=\\frac{1}{\\sqrt{2\\pi\\epsilon^{2}}}\\exp\\left(-\\frac{\\left(y_{i}-\\phi_{w}(x_{i})\\right)^{2}}{2\\epsilon^{2}}\\right)$$\n",
    "\n",
    "$$\\Rightarrow-\\ln\\left(p(y_{i}\\mid x_{i},w)\\right)\\Big|_{\\{w,\\epsilon\\}}=-\\ln(\\epsilon)-\\frac{\\left(y_{i}-\\phi_{w}(x_{i})\\right)^{2}}{2\\epsilon^{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define using keras (K) the second term of the above formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(y, output_psi, epsilon):\n",
    "    return -K.log(epsilon) - K.square(y - output_psi)/(2 * K.square(epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom keras' layer to deal with scalars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queremos crear nuestra capa para entrenar el parámetro epsilon\n",
    "# plantilla aquí https://keras.io/layers/writing-your-own-keras-layers/\n",
    "\n",
    "class Scalar(Layer):\n",
    "    \n",
    "    def __init__(self, unit=1, initializer=K.zeros,\n",
    "                 activation = None,\n",
    "                 **kwargs):\n",
    "        #self.output_dim = output_dim\n",
    "        #self.output_dim = unit\n",
    "        \n",
    "        self.scalar_initializer = initializer\n",
    "        self.units = unit\n",
    "        self.activation = activation\n",
    "        super(Scalar, self).__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    def build(self, bs_input):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.scalar = self.add_weight(name='sigma_hom', \n",
    "                                      #shape=(input_shape[1], self.output_dim),\n",
    "                                      shape=[self.units],\n",
    "                                      initializer=self.scalar_initializer,\n",
    "                                      trainable=True)\n",
    "        self.params = [self.scalar]\n",
    "        #super(Scalar, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, bs_input):\n",
    "        output = self.scalar * K.ones_like(bs_input[:,:1]) # esta capa devuelve una\n",
    "        # matriz de una columna sea cual sea el tensor que se le pase\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_output(self, train=False):\n",
    "        output = self.scalar * K.ones(self.get_input()[:,:1])\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a function which retuns the ELU value of x + 1 given x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import ELU\n",
    "\n",
    "def elu_plus1(x, a=1.):\n",
    "    return ELU(alpha=a)(x)+1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos nuestra funcion de perdida\n",
    "def regression(y_true, parameters):\n",
    "    mu = parameters[:, :-1] # todas las columnas menos la última\n",
    "    sigma = parameters[:,-1]\n",
    "    return -K.sum(log_normal_pdf(y_true[:,:1], mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo de modo funcional (necesariamente)\n",
    "\n",
    "i = Input(name='input', shape = (1,), dtype='float32')\n",
    "phi = Dense(units = 1, activation = 'linear', name = 'w', kernel_initializer='ones')(i)\n",
    "\n",
    "epsilon = Scalar(activation = elu_plus1)(i)\n",
    "\n",
    "model = Model(inputs =[i], outputs = [concatenate([phi, epsilon],\n",
    "                                                 axis = 1,\n",
    "                                                 name = 'main_output')])\n",
    "\n",
    "\n",
    "opt = Adam(lr = 0.1)\n",
    "model.compile(optimizer = opt,\n",
    "             loss={'main_output':regression}) # esto nos permite asignar diferentes losses a diferentes capas de salida\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 0s 693us/step - loss: 1189.9056 - val_loss: 257.8416\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 173us/step - loss: 701.0110 - val_loss: 170.1759\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 0us/step - loss: 472.8476 - val_loss: 124.5884\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 184us/step - loss: 351.7125 - val_loss: 98.0280\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 279.9093 - val_loss: 81.2191\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 234.1712 - val_loss: 69.8821\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 89us/step - loss: 202.8301 - val_loss: 61.8459\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 179.0356 - val_loss: 55.9371\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 162.7125 - val_loss: 51.4206\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 150.0451 - val_loss: 47.8706\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 139.5927 - val_loss: 45.0101\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 78us/step - loss: 131.2379 - val_loss: 42.6520\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 124.5625 - val_loss: 40.6653\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 118.7653 - val_loss: 38.9629\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 113.6605 - val_loss: 37.4818\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 109.2270 - val_loss: 36.1733\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 105.7043 - val_loss: 35.0004\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 102.0777 - val_loss: 33.9405\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 98.9595 - val_loss: 32.9731\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 96.2791 - val_loss: 32.0793\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 93.4550 - val_loss: 31.2542\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 90.9834 - val_loss: 30.4859\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 88.8169 - val_loss: 29.7651\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 86.4975 - val_loss: 29.0885\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 84.6020 - val_loss: 28.4495\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 82.5710 - val_loss: 27.8455\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 80.8585 - val_loss: 27.2721\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 79.2054 - val_loss: 26.7265\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 77.6591 - val_loss: 26.2068\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 76.2572 - val_loss: 25.7098\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 74.6938 - val_loss: 25.2357\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 73.2233 - val_loss: 24.7829\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.8805 - val_loss: 24.3503\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 70.6087 - val_loss: 23.9351\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 69.4286 - val_loss: 23.5367\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.3177 - val_loss: 23.1533\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 67.1106 - val_loss: 22.7853\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 66.0012 - val_loss: 22.4315\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 65.0826 - val_loss: 22.0896\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 63.8876 - val_loss: 21.7627\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 63.1694 - val_loss: 21.4458\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 62.1331 - val_loss: 21.1410\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 61.2395 - val_loss: 20.8474\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 60.4797 - val_loss: 20.5628\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 59.5498 - val_loss: 20.2888\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 58.8488 - val_loss: 20.0237\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 58.1985 - val_loss: 19.7656\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 57.3339 - val_loss: 19.5174\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 56.6045 - val_loss: 19.2770\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 56.0117 - val_loss: 19.0440\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 55.2602 - val_loss: 18.8191\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 54.8178 - val_loss: 18.5990\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 54.0938 - val_loss: 18.3866\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 53.3851 - val_loss: 18.1810\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 52.9634 - val_loss: 17.9804\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 52.3625 - val_loss: 17.7860\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 51.9125 - val_loss: 17.5962\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 51.1828 - val_loss: 17.4138\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 50.6445 - val_loss: 17.2366\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 50.1658 - val_loss: 17.0640\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 49.6797 - val_loss: 16.8958\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 49.1156 - val_loss: 16.7327\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 48.8132 - val_loss: 16.5723\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 48.4227 - val_loss: 16.4160\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 47.8939 - val_loss: 16.2643\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 47.4373 - val_loss: 16.1171\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 22us/step - loss: 47.0354 - val_loss: 15.9736\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 46.7181 - val_loss: 15.8325\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 46.2818 - val_loss: 15.6949\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 45.9417 - val_loss: 15.5607\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 45.6002 - val_loss: 15.4294\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 45.1926 - val_loss: 15.3019\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 44.8540 - val_loss: 15.1777\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 44.5130 - val_loss: 15.0559\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 44.2287 - val_loss: 14.9359\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 43.7537 - val_loss: 14.8202\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 43.4434 - val_loss: 14.7069\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 43.2044 - val_loss: 14.5954\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 42.8643 - val_loss: 14.4862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 42.6103 - val_loss: 14.3792\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 42.2486 - val_loss: 14.2749\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 41.9782 - val_loss: 14.1726\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 41.7390 - val_loss: 14.0717\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 41.4539 - val_loss: 13.9732\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 41.1371 - val_loss: 13.8768\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 40.8836 - val_loss: 13.7822\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 40.6202 - val_loss: 13.6892\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 40.4371 - val_loss: 13.5970\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 40.1304 - val_loss: 13.5073\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 39.8711 - val_loss: 13.4193\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 39.6281 - val_loss: 13.3329\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 39.4571 - val_loss: 13.2475\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 39.1458 - val_loss: 13.1642\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 38.9123 - val_loss: 13.0822\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 38.7095 - val_loss: 13.0011\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 38.5269 - val_loss: 12.9210\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 38.2553 - val_loss: 12.8421\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 38.0580 - val_loss: 12.7648\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 37.8106 - val_loss: 12.6887\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 37.5703 - val_loss: 12.6136\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 37.4152 - val_loss: 12.5389\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 37.1853 - val_loss: 12.4657\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 37.0073 - val_loss: 12.3929\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 36.7880 - val_loss: 12.3213\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 36.5983 - val_loss: 12.2504\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 36.3839 - val_loss: 12.1805\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 36.2355 - val_loss: 12.1108\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 36.0150 - val_loss: 12.0424\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 35.8242 - val_loss: 11.9743\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 35.6109 - val_loss: 11.9072\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 35.4315 - val_loss: 11.8405\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 35.2706 - val_loss: 11.7740\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 35.0590 - val_loss: 11.7083\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 34.8736 - val_loss: 11.6430\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 34.7167 - val_loss: 11.5779\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 34.5338 - val_loss: 11.5133\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 34.3417 - val_loss: 11.4491\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 34.1373 - val_loss: 11.3854\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 33.9517 - val_loss: 11.3219\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 33.7907 - val_loss: 11.2584\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 33.6054 - val_loss: 11.1952\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 33.4172 - val_loss: 11.1322\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 33.2330 - val_loss: 11.0693\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 33.0445 - val_loss: 11.0065\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 32.8696 - val_loss: 10.9438\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 32.6883 - val_loss: 10.8808\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 22us/step - loss: 32.5326 - val_loss: 10.8175\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 32.3285 - val_loss: 10.7544\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 32.1367 - val_loss: 10.6913\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 31.9643 - val_loss: 10.6279\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 31.7724 - val_loss: 10.5644\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 31.5812 - val_loss: 10.5007\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 31.4018 - val_loss: 10.4366\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 31.2124 - val_loss: 10.3723\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 31.0157 - val_loss: 10.3076\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 30.8303 - val_loss: 10.2425\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 30.6434 - val_loss: 10.1769\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 30.4334 - val_loss: 10.1109\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 30.2460 - val_loss: 10.0444\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 30.0450 - val_loss: 9.9773\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 29.8409 - val_loss: 9.9096\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 29.6564 - val_loss: 9.8411\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 29.4408 - val_loss: 9.7720\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 29.2272 - val_loss: 9.7022\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 29.0279 - val_loss: 9.6316\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 28.8169 - val_loss: 9.5603\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 28.5976 - val_loss: 9.4879\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 28.3739 - val_loss: 9.4148\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 28.1574 - val_loss: 9.3408\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 27.9397 - val_loss: 9.2657\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 27.7027 - val_loss: 9.1893\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 27.4753 - val_loss: 9.1119\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 27.2362 - val_loss: 9.0335\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 26.9992 - val_loss: 8.9540\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 26.7606 - val_loss: 8.8731\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 26.5140 - val_loss: 8.7906\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 26.2561 - val_loss: 8.7069\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 25.9963 - val_loss: 8.6216\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 25.7508 - val_loss: 8.5348\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 25.4849 - val_loss: 8.4465\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 25.2090 - val_loss: 8.3568\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 24.9338 - val_loss: 8.2649\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 24.6591 - val_loss: 8.1713\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 24.3649 - val_loss: 8.0757\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 24.0645 - val_loss: 7.9782\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 23.7752 - val_loss: 7.8788\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 23.4619 - val_loss: 7.7771\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 23.1559 - val_loss: 7.6731\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 22.8188 - val_loss: 7.5668\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 22.5021 - val_loss: 7.4579\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 22.1635 - val_loss: 7.3469\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 21.8248 - val_loss: 7.2328\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 21.4664 - val_loss: 7.1161\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 21.1082 - val_loss: 6.9966\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 20.7381 - val_loss: 6.8739\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 20.3629 - val_loss: 6.7480\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 19.9529 - val_loss: 6.6183\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 19.5634 - val_loss: 6.4854\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 19.1561 - val_loss: 6.3485\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 18.7124 - val_loss: 6.2082\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 18.2753 - val_loss: 6.0632\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 17.8299 - val_loss: 5.9140\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 17.3586 - val_loss: 5.7597\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 16.8754 - val_loss: 5.6002\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 16.3720 - val_loss: 5.4364\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 15.8449 - val_loss: 5.2669\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 15.3158 - val_loss: 5.0915\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 14.7668 - val_loss: 4.9093\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 14.1967 - val_loss: 4.7220\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 13.5879 - val_loss: 4.5274\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 12.9804 - val_loss: 4.3250\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 12.3262 - val_loss: 4.1125\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 11.6376 - val_loss: 3.8930\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 10.9115 - val_loss: 3.6641\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 10.1940 - val_loss: 3.4247\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 22us/step - loss: 9.4271 - val_loss: 3.1757\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 8.6210 - val_loss: 2.9132\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 7.7876 - val_loss: 2.6373\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 6.8495 - val_loss: 2.3476\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 5.9403 - val_loss: 2.0421\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 4.9393 - val_loss: 1.7250\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 3.8655 - val_loss: 1.3889\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 2.7586 - val_loss: 1.0345\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 1.5769 - val_loss: 0.6726\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 0.3605 - val_loss: 0.3222\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -0.7907 - val_loss: -0.0172\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -2.0667 - val_loss: -0.3401\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -3.1688 - val_loss: -0.6619\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -4.4493 - val_loss: -0.9795\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -5.4271 - val_loss: -1.2509\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -6.5067 - val_loss: -1.5125\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -7.5289 - val_loss: -1.7677\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -8.4049 - val_loss: -1.9313\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -9.2520 - val_loss: -2.1410\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -10.1520 - val_loss: -2.3260\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -10.7966 - val_loss: -2.3788\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -11.5085 - val_loss: -2.4426\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -12.0325 - val_loss: -2.4736\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -12.7404 - val_loss: -2.5750\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -12.9292 - val_loss: -2.6443\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -13.4636 - val_loss: -2.6751\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -13.6790 - val_loss: -2.5505\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.1009 - val_loss: -2.6384\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.3888 - val_loss: -2.6866\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.3132 - val_loss: -2.7495\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.3923 - val_loss: -2.2729\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.6474 - val_loss: -2.3590\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7033 - val_loss: -2.4853\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8574 - val_loss: -2.2151\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0792 - val_loss: -2.2341\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0765 - val_loss: -2.3659\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0655 - val_loss: -2.2675\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9694 - val_loss: -1.9149\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2211 - val_loss: -2.0094\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7857 - val_loss: -2.1201\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0048 - val_loss: -2.1276\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7989 - val_loss: -1.8938\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 44us/step - loss: -14.9232 - val_loss: -1.8981\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9658 - val_loss: -2.0411\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7002 - val_loss: -2.2150\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8134 - val_loss: -1.9989\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.3562 - val_loss: -1.7533\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9245 - val_loss: -1.8940\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8146 - val_loss: -2.0829\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.3533 - val_loss: -2.0862\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8508 - val_loss: -2.1654\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8475 - val_loss: -1.8810\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0955 - val_loss: -1.8393\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0675 - val_loss: -2.1161\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 100us/step - loss: -14.9307 - val_loss: -2.2372\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7661 - val_loss: -1.7713\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7154 - val_loss: -1.6174\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8997 - val_loss: -2.3001\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8724 - val_loss: -2.1260\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7967 - val_loss: -1.8835\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0196 - val_loss: -1.6500\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.5257 - val_loss: -1.9546\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7127 - val_loss: -2.3788\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0611 - val_loss: -2.1503\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9351 - val_loss: -1.7871\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.6619 - val_loss: -1.5859\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9461 - val_loss: -2.3154\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.3093 - val_loss: -2.2535\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.5880 - val_loss: -1.7988\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.3475 - val_loss: -2.0488\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9155 - val_loss: -1.9657\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.6316 - val_loss: -2.0621\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8145 - val_loss: -2.3578\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0074 - val_loss: -2.2439\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2149 - val_loss: -1.5866\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.5587 - val_loss: -1.8156\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2542 - val_loss: -2.1362\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1310 - val_loss: -2.3356\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7836 - val_loss: -2.1914\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0145 - val_loss: -1.9424\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.6262 - val_loss: -1.6984\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1819 - val_loss: -1.7184\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8671 - val_loss: -2.0768\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8332 - val_loss: -2.2015\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0641 - val_loss: -2.4184\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.6789 - val_loss: -1.8864\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8496 - val_loss: -1.5116\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7558 - val_loss: -1.9569\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2880 - val_loss: -1.9409\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9282 - val_loss: -2.3459\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -15.0360 - val_loss: -2.4053\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.4447 - val_loss: -1.8087\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1911 - val_loss: -1.7129\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9544 - val_loss: -2.2588\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: -14.9420 - val_loss: -2.2229\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9940 - val_loss: -1.9083\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8685 - val_loss: -1.8584\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0191 - val_loss: -1.7943\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0582 - val_loss: -2.1532\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7529 - val_loss: -2.0110\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1036 - val_loss: -2.0493\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1269 - val_loss: -2.1413\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9435 - val_loss: -1.7883\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.4995 - val_loss: -2.2077\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0279 - val_loss: -2.2317\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9951 - val_loss: -1.9605\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.3002 - val_loss: -1.8664\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.4327 - val_loss: -1.9185\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.6680 - val_loss: -2.0896\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9754 - val_loss: -2.2663\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0262 - val_loss: -2.1720\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1196 - val_loss: -1.9172\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9311 - val_loss: -1.9158\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9595 - val_loss: -2.0647\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2618 - val_loss: -1.8758\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2114 - val_loss: -2.0511\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0283 - val_loss: -1.9891\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1830 - val_loss: -1.8278\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8008 - val_loss: -2.0758\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0925 - val_loss: -2.2696\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8040 - val_loss: -2.0768\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8559 - val_loss: -1.7415\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.6229 - val_loss: -1.9800\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2983 - val_loss: -1.7588\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7474 - val_loss: -1.9959\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7828 - val_loss: -2.4874\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9895 - val_loss: -2.1047\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9019 - val_loss: -1.5564\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8890 - val_loss: -2.0182\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2061 - val_loss: -2.1311\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1760 - val_loss: -2.2320\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8745 - val_loss: -2.0079\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0865 - val_loss: -2.0774\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0661 - val_loss: -1.9072\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9142 - val_loss: -2.1691\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.4373 - val_loss: -2.1669\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1561 - val_loss: -1.8689\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8136 - val_loss: -1.9213\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8226 - val_loss: -1.9059\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1085 - val_loss: -2.0611\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0860 - val_loss: -2.2375\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8573 - val_loss: -1.9818\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2413 - val_loss: -2.0040\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9740 - val_loss: -2.0429\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7049 - val_loss: -1.9342\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9043 - val_loss: -2.1141\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1898 - val_loss: -1.9205\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1668 - val_loss: -1.9826\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0665 - val_loss: -2.1315\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -14.7087 - val_loss: -2.0456\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7698 - val_loss: -2.1368\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8378 - val_loss: -1.7647\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0117 - val_loss: -2.1187\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8261 - val_loss: -2.1004\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.5995 - val_loss: -2.1637\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8304 - val_loss: -1.8137\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -14.7393 - val_loss: -1.9237\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9479 - val_loss: -2.1728\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 22us/step - loss: -14.8591 - val_loss: -2.1811\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2197 - val_loss: -1.8518\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0673 - val_loss: -1.9363\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.3264 - val_loss: -1.9728\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7355 - val_loss: -2.2107\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8144 - val_loss: -2.1071\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7043 - val_loss: -1.8687\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9796 - val_loss: -2.1976\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1250 - val_loss: -2.0942\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9503 - val_loss: -1.8367\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -15.0722 - val_loss: -1.9079\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0545 - val_loss: -2.0494\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2943 - val_loss: -2.1926\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8345 - val_loss: -1.9746\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7635 - val_loss: -2.0122\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1468 - val_loss: -1.7536\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.5948 - val_loss: -1.8878\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -14.9543 - val_loss: -2.2026\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0324 - val_loss: -2.1151\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8842 - val_loss: -2.1670\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9911 - val_loss: -1.8342\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9211 - val_loss: -1.5755\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9484 - val_loss: -2.1362\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.5551 - val_loss: -2.4671\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7698 - val_loss: -2.0970\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2481 - val_loss: -1.8560\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -14.9367 - val_loss: -1.7491\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.6133 - val_loss: -2.2235\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9701 - val_loss: -2.1429\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8103 - val_loss: -2.1190\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2663 - val_loss: -1.8816\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.6154 - val_loss: -1.5462\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9778 - val_loss: -1.9952\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.5511 - val_loss: -2.3066\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0686 - val_loss: -2.4800\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.6303 - val_loss: -2.0320\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.3351 - val_loss: -1.5726\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0224 - val_loss: -1.8763\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1785 - val_loss: -2.0607\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9168 - val_loss: -2.1690\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 33us/step - loss: -15.2316 - val_loss: -1.9920\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0370 - val_loss: -2.1098\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1700 - val_loss: -2.3193\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8905 - val_loss: -1.9677\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9385 - val_loss: -2.0512\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.3336 - val_loss: -1.5913\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8296 - val_loss: -1.8125\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.3157 - val_loss: -2.2074\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2181 - val_loss: -2.4176\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2115 - val_loss: -1.9562\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8760 - val_loss: -1.6430\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1459 - val_loss: -1.7708\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9222 - val_loss: -2.2910\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9487 - val_loss: -2.4115\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9454 - val_loss: -2.0124\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8058 - val_loss: -2.0465\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9873 - val_loss: -1.7993\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0651 - val_loss: -2.2325\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1363 - val_loss: -2.2657\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.4958 - val_loss: -1.7834\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9969 - val_loss: -1.8841\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2146 - val_loss: -1.8963\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0060 - val_loss: -1.9485\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2255 - val_loss: -2.0069\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2586 - val_loss: -2.1513\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -14.8050 - val_loss: -2.2416\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: -14.7644 - val_loss: -2.1920\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -14.8928 - val_loss: -1.9475\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7504 - val_loss: -1.7614\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1209 - val_loss: -1.7742\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1271 - val_loss: -2.4188\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9275 - val_loss: -2.3267\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8413 - val_loss: -1.8434\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9449 - val_loss: -1.8671\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2104 - val_loss: -1.9423\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0034 - val_loss: -1.7726\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0632 - val_loss: -2.2506\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2511 - val_loss: -2.1890\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8323 - val_loss: -2.1026\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.6287 - val_loss: -2.0166\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0031 - val_loss: -2.0455\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9101 - val_loss: -1.8887\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0992 - val_loss: -1.8830\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0610 - val_loss: -2.1678\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1852 - val_loss: -2.0793\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9772 - val_loss: -2.0666\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7079 - val_loss: -1.9127\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8584 - val_loss: -2.0313\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2321 - val_loss: -1.9645\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.6098 - val_loss: -2.0945\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: -14.9965 - val_loss: -1.9915\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0471 - val_loss: -1.9434\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9799 - val_loss: -2.1087\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1520 - val_loss: -2.0144\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0370 - val_loss: -2.0816\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.3002 - val_loss: -2.0935\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7329 - val_loss: -1.7760\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.4033 - val_loss: -1.9748\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.3760 - val_loss: -2.1499\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.2211 - val_loss: -1.8131\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0391 - val_loss: -2.0530\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2268 - val_loss: -1.8259\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7736 - val_loss: -2.2628\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.3331 - val_loss: -2.2678\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.4003 - val_loss: -2.0068\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7111 - val_loss: -1.7737\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8567 - val_loss: -1.8449\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7724 - val_loss: -2.0729\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9048 - val_loss: -2.0388\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0273 - val_loss: -2.0038\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0200 - val_loss: -2.1536\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0229 - val_loss: -1.8947\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8969 - val_loss: -1.7772\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9565 - val_loss: -2.1954\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2434 - val_loss: -2.2197\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1549 - val_loss: -2.0243\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0047 - val_loss: -1.7663\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.4251 - val_loss: -1.8915\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0764 - val_loss: -1.9638\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9509 - val_loss: -2.1127\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.4261 - val_loss: -2.1430\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7952 - val_loss: -1.9387\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8579 - val_loss: -1.9103\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.6590 - val_loss: -1.7765\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7538 - val_loss: -2.3322\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0137 - val_loss: -2.2580\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.9382 - val_loss: -1.5489\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.8792 - val_loss: -1.8709\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1772 - val_loss: -1.9852\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.5879 - val_loss: -2.4812\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0041 - val_loss: -1.9927\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.2021 - val_loss: -1.4863\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.0480 - val_loss: -1.9888\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.6723 - val_loss: -2.4619\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1550 - val_loss: -2.0476\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1974 - val_loss: -1.7591\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.6860 - val_loss: -2.0108\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.8048 - val_loss: -2.2907\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7459 - val_loss: -2.2585\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.1889 - val_loss: -1.8862\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.6108 - val_loss: -1.6414\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.7110 - val_loss: -2.0359\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9253 - val_loss: -2.3284\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -14.9669 - val_loss: -2.1874\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -15.0938 - val_loss: -1.8330\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: -14.7597 - val_loss: -1.7070\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: -15.1813 - val_loss: -1.9258\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train.reshape(-1,1), # pasamos el array como matriz\n",
    "                    np.repeat(y_train.reshape(-1,1), 2, axis = 1), # duplicamos las y-es para pasarlo a las  dos capas\n",
    "                    # aunque parece que no es obligatoria esta redimensión\n",
    "                    epochs = 500,\n",
    "                    validation_split = .1,\n",
    "                    verbose = 1\n",
    "                    \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the predictions and visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = np.arange(low,high,0.01).reshape(-1,1)\n",
    "y_test = f(X_test) + np.random.normal(\n",
    "    0,std,size=(X_test.shape[0])).reshape(-1,1)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "plt.errorbar(X_test,prediction[:,0], # mu\n",
    "             yerr=2*prediction[:,1], # epsilon\n",
    "             color='#0A5FB4',\n",
    "             alpha=0.8,\n",
    "             label='prediction')\n",
    "\n",
    "plt.plot(X_test, y_test,'x',c='r',\n",
    "         alpha=0.8, label='real generated data')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos aprendido tanto el modelo como el intervalo de confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable noise\n",
    "\n",
    "Let's now assume that our noise is not constant but a function of x:\n",
    "\n",
    "$$y = f(x) + \\epsilon(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, generate the data according to this new condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "std = 0.4\n",
    "epsilon = np.random.normal(0,std, size = points)\n",
    "\n",
    "y_train = f(x_train) + epsilon + [np.random.normal(0,i) for i in (np.sin(x_train*-10))+1]\n",
    "\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have $$y = \\phi_w (x) + \\psi_v (x)$$\n",
    "\n",
    "$$ p(y \\mid x, w, v) = \\mathcal{N}(y \\mid \\phi_w(x), \\psi_v^2(x))=$$\n",
    "            $$= \\frac{1}{\\sqrt{2\\pi \\psi_v(x)^2}} e^{-\\frac{(y-\\phi_w (x))^2}{2\\psi_v(x)^2}}$$\n",
    "\n",
    "i.e. We estimate a variability of $y_i$ for every data point $x_i$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the new regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo de modo funcional (necesariamente)\n",
    "#K.clear_session()\n",
    "i = Input(name='input', shape = (1,), dtype='float32')\n",
    "phi = Dense(units = 1, activation = 'linear', name = 'w', kernel_initializer='ones')(i)\n",
    "\n",
    "psi = Dense(units=12, activation = 'sigmoid', name='v_0')(i)\n",
    "psi = Dense(units = 6, activation = 'sigmoid', name='v_1')(psi)\n",
    "psi = Dense(units = 1, activation = elu_plus1, name='v_2')(psi)\n",
    "\n",
    "#epsilon = Scalar(activation = elu_plus1)(i)\n",
    "\n",
    "model = Model(inputs =[i], outputs = [concatenate([phi, psi],\n",
    "                                                 axis = 1,\n",
    "                                                 name = 'main_output')])\n",
    "\n",
    "\n",
    "opt = Adam(lr = 0.01)\n",
    "model.compile(optimizer = opt,\n",
    "             loss={'main_output':regression}) # esto nos permite asignar diferentes losses a diferentes capas de salida\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2046.2872 - val_loss: 420.0049\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 229us/step - loss: 1251.7411 - val_loss: 278.6396\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 848.0575 - val_loss: 208.2592\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 651.8794 - val_loss: 168.2094\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 531.3543 - val_loss: 143.1821\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 456.5245 - val_loss: 126.3510\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 405.5931 - val_loss: 114.3852\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 372.5745 - val_loss: 105.4764\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 344.0420 - val_loss: 98.6226\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 324.0690 - val_loss: 93.1792\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 307.1002 - val_loss: 88.7504\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 291.7544 - val_loss: 85.0711\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 278.3658 - val_loss: 81.9490\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 268.5414 - val_loss: 79.2463\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 260.1984 - val_loss: 76.8678\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 253.5838 - val_loss: 74.7497\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 245.2587 - val_loss: 72.8486\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 239.4553 - val_loss: 71.1116\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 234.2138 - val_loss: 69.5162\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 228.8873 - val_loss: 68.0418\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 224.2209 - val_loss: 66.6648\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 219.5297 - val_loss: 65.3793\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 214.3458 - val_loss: 64.1716\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 211.6981 - val_loss: 63.0258\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 206.3565 - val_loss: 61.9436\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 202.4779 - val_loss: 60.9140\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 199.5609 - val_loss: 59.9278\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 196.5189 - val_loss: 58.9849\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 193.2184 - val_loss: 58.0811\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 190.7557 - val_loss: 57.2115\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 187.4125 - val_loss: 56.3749\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 183.0795 - val_loss: 55.5732\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 181.6010 - val_loss: 54.7948\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 178.1528 - val_loss: 54.0434\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 176.5680 - val_loss: 53.3125\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 175.3711 - val_loss: 52.5999\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 171.7958 - val_loss: 51.9139\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 170.3747 - val_loss: 51.2447\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 166.9565 - val_loss: 50.5960\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 165.2139 - val_loss: 49.9641\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 163.2339 - val_loss: 49.3477\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 161.0762 - val_loss: 48.7481\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 158.6798 - val_loss: 48.1653\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 156.9766 - val_loss: 47.5966\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 155.0772 - val_loss: 47.0429\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 152.6883 - val_loss: 46.5057\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 151.3773 - val_loss: 45.9805\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 149.9426 - val_loss: 45.4703\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 147.4445 - val_loss: 44.9785\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 146.5043 - val_loss: 44.4990\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 144.8062 - val_loss: 44.0337\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 143.3665 - val_loss: 43.5844\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 141.4820 - val_loss: 43.1512\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 140.3023 - val_loss: 42.7317\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 138.6911 - val_loss: 42.3260\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 136.6728 - val_loss: 41.9358\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 135.8353 - val_loss: 41.5577\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 135.1678 - val_loss: 41.1920\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 133.2586 - val_loss: 40.8409\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 132.3386 - val_loss: 40.5011\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 131.2590 - val_loss: 40.1726\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 130.0665 - val_loss: 39.8556\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 129.5373 - val_loss: 39.5478\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 127.7504 - val_loss: 39.2518\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 126.8241 - val_loss: 38.9657\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 126.3562 - val_loss: 38.6873\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 124.7546 - val_loss: 38.4188\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 124.1156 - val_loss: 38.1573\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 123.2550 - val_loss: 37.9049\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 122.5812 - val_loss: 37.6597\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 121.4524 - val_loss: 37.4221\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 121.1656 - val_loss: 37.1894\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 119.5557 - val_loss: 36.9660\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 119.2394 - val_loss: 36.7478\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 118.1882 - val_loss: 36.5358\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 117.6010 - val_loss: 36.3294\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 117.2593 - val_loss: 36.1281\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 116.7949 - val_loss: 35.9317\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 115.7474 - val_loss: 35.7415\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 115.3010 - val_loss: 35.5556\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 114.5382 - val_loss: 35.3747\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 113.4235 - val_loss: 35.1985\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 113.7717 - val_loss: 35.0254\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 112.4492 - val_loss: 34.8579\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 111.9535 - val_loss: 34.6936\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 111.1091 - val_loss: 34.5338\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 78us/step - loss: 110.6346 - val_loss: 34.3775\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 110.4876 - val_loss: 34.2246\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 110.2668 - val_loss: 34.0737\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 109.5658 - val_loss: 33.9273\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 108.6897 - val_loss: 33.7847\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 108.6711 - val_loss: 33.6441\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 108.1572 - val_loss: 33.5064\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 107.3232 - val_loss: 33.3723\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 106.8862 - val_loss: 33.2409\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 106.5167 - val_loss: 33.1122\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 106.2086 - val_loss: 32.9858\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 105.9780 - val_loss: 32.8616\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 104.9748 - val_loss: 32.7409\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 105.0030 - val_loss: 32.6216\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 104.6600 - val_loss: 32.5049\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 104.3540 - val_loss: 32.3901\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 103.7882 - val_loss: 32.2778\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 103.4945 - val_loss: 32.1676\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 102.7017 - val_loss: 32.0603\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 102.0955 - val_loss: 31.9548\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 102.1593 - val_loss: 31.8503\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 101.6915 - val_loss: 31.7481\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 101.4559 - val_loss: 31.6474\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 100.8072 - val_loss: 31.5489\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 100.6035 - val_loss: 31.4520\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 100.8574 - val_loss: 31.3558\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 100.4287 - val_loss: 31.2616\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 100.0760 - val_loss: 31.1692\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 99.5771 - val_loss: 31.0787\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 99.3173 - val_loss: 30.9898\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 98.8647 - val_loss: 30.9023\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 98.7665 - val_loss: 30.8158\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 98.4060 - val_loss: 30.7309\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 98.0453 - val_loss: 30.6476\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 97.8567 - val_loss: 30.5654\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 97.6123 - val_loss: 30.4845\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 97.1205 - val_loss: 30.4052\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 96.8893 - val_loss: 30.3270\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 96.8970 - val_loss: 30.2496\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 96.2712 - val_loss: 30.1737\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 96.2074 - val_loss: 30.0989\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 96.1505 - val_loss: 30.0249\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 95.9092 - val_loss: 29.9520\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 95.2994 - val_loss: 29.8804\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 95.1731 - val_loss: 29.8101\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 94.9358 - val_loss: 29.7406\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 94.8808 - val_loss: 29.6719\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 94.5018 - val_loss: 29.6044\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 94.4532 - val_loss: 29.5372\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 94.4770 - val_loss: 29.4710\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 93.8497 - val_loss: 29.4063\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 93.5464 - val_loss: 29.3427\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 92.9541 - val_loss: 29.2801\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 92.8063 - val_loss: 29.2181\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 93.2290 - val_loss: 29.1564\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 92.5599 - val_loss: 29.0959\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 92.7276 - val_loss: 29.0359\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 92.3424 - val_loss: 28.9766\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 92.0877 - val_loss: 28.9186\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 92.0397 - val_loss: 28.8610\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 91.8051 - val_loss: 28.8044\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 91.4288 - val_loss: 28.7487\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 91.1037 - val_loss: 28.6935\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 91.2883 - val_loss: 28.6387\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 90.7686 - val_loss: 28.5849\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 90.7145 - val_loss: 28.5316\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 90.6786 - val_loss: 28.4790\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 90.3112 - val_loss: 28.4271\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 89.9972 - val_loss: 28.3758\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 90.0361 - val_loss: 28.3250\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 44us/step - loss: 90.0578 - val_loss: 28.2745\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 89.6213 - val_loss: 28.2249\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 89.4932 - val_loss: 28.1761\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 89.3834 - val_loss: 28.1276\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 89.1853 - val_loss: 28.0798\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 88.9599 - val_loss: 28.0326\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 88.6914 - val_loss: 27.9858\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 88.4767 - val_loss: 27.9398\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 88.3953 - val_loss: 27.8940\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 88.2389 - val_loss: 27.8490\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 88.1614 - val_loss: 27.8043\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 88.2217 - val_loss: 27.7598\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 87.7162 - val_loss: 27.7163\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 87.6617 - val_loss: 27.6731\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 87.7403 - val_loss: 27.6303\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 87.3945 - val_loss: 27.5880\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 86.9998 - val_loss: 27.5464\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 87.2809 - val_loss: 27.5047\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 86.9575 - val_loss: 27.4637\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 86.8159 - val_loss: 27.4232\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 86.5865 - val_loss: 27.3832\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 86.3105 - val_loss: 27.3436\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 86.5296 - val_loss: 27.3040\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 86.2679 - val_loss: 27.2650\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 86.1529 - val_loss: 27.2266\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 86.1471 - val_loss: 27.1884\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 85.8196 - val_loss: 27.1507\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 85.7786 - val_loss: 27.1134\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 85.8026 - val_loss: 27.0763\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 85.3710 - val_loss: 27.0398\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 85.5715 - val_loss: 27.0033\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 85.2290 - val_loss: 26.9675\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 84.9142 - val_loss: 26.9322\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 84.9016 - val_loss: 26.8971\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 84.8765 - val_loss: 26.8621\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 84.9612 - val_loss: 26.8272\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 84.6271 - val_loss: 26.7930\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 84.4484 - val_loss: 26.7592\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 84.4749 - val_loss: 26.7255\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 84.5466 - val_loss: 26.6919\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 84.0119 - val_loss: 26.6592\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 84.0062 - val_loss: 26.6265\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 84.0075 - val_loss: 26.5940\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 84.0042 - val_loss: 26.5618\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 83.7392 - val_loss: 26.5301\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 83.6302 - val_loss: 26.4984\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 83.5601 - val_loss: 26.4671\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 83.3267 - val_loss: 26.4361\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 83.1664 - val_loss: 26.4056\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 83.0953 - val_loss: 26.3751\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 82.9917 - val_loss: 26.3450\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 83.0657 - val_loss: 26.3149\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 82.8057 - val_loss: 26.2853\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 82.8227 - val_loss: 26.2558\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 82.4491 - val_loss: 26.2268\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 82.4960 - val_loss: 26.1978\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 82.3949 - val_loss: 26.1692\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 82.4099 - val_loss: 26.1407\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 82.1760 - val_loss: 26.1125\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 81.9917 - val_loss: 26.0845\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 82.0981 - val_loss: 26.0566\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 82.0577 - val_loss: 26.0290\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 81.9453 - val_loss: 26.0016\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 81.6875 - val_loss: 25.9747\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 81.8394 - val_loss: 25.9476\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 81.6998 - val_loss: 25.9208\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 81.5728 - val_loss: 25.8943\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 81.5941 - val_loss: 25.8680\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 81.3233 - val_loss: 25.8420\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 81.2002 - val_loss: 25.8162\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 81.2175 - val_loss: 25.7905\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 81.1488 - val_loss: 25.7650\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 80.9694 - val_loss: 25.7397\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 80.9296 - val_loss: 25.7147\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 80.6608 - val_loss: 25.6899\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 80.7281 - val_loss: 25.6651\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 80.4562 - val_loss: 25.6407\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 80.4042 - val_loss: 25.6164\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 80.5584 - val_loss: 25.5921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 80.4102 - val_loss: 25.5681\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 80.4005 - val_loss: 25.5441\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.9847 - val_loss: 25.5206\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 80.2097 - val_loss: 25.4971\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 80.0780 - val_loss: 25.4738\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.9587 - val_loss: 25.4506\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 79.9304 - val_loss: 25.4275\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.8900 - val_loss: 25.4047\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 79.5570 - val_loss: 25.3821\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.7372 - val_loss: 25.3595\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 79.4764 - val_loss: 25.3372\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.5064 - val_loss: 25.3149\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.3334 - val_loss: 25.2929\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.2339 - val_loss: 25.2710\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.2259 - val_loss: 25.2492\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.9738 - val_loss: 25.2276\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 79.1554 - val_loss: 25.2060\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.1227 - val_loss: 25.1846\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 79.0194 - val_loss: 25.1633\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.9931 - val_loss: 25.1422\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.8498 - val_loss: 25.1213\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.6267 - val_loss: 25.1005\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.7820 - val_loss: 25.0798\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 78.8265 - val_loss: 25.0591\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.5405 - val_loss: 25.0387\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 78.6559 - val_loss: 25.0184\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.5291 - val_loss: 24.9983\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.2605 - val_loss: 24.9783\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 78.2312 - val_loss: 24.9583\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 78.1006 - val_loss: 24.9386\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.0030 - val_loss: 24.9189\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 78.0574 - val_loss: 24.8993\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.9065 - val_loss: 24.8799\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.9079 - val_loss: 24.8606\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.9492 - val_loss: 24.8413\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 77.8583 - val_loss: 24.8221\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.6994 - val_loss: 24.8031\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 77.5389 - val_loss: 24.7843\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.5089 - val_loss: 24.7656\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.5360 - val_loss: 24.7469\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.2639 - val_loss: 24.7284\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 77.3065 - val_loss: 24.7100\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.4537 - val_loss: 24.6915\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.1853 - val_loss: 24.6733\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.3348 - val_loss: 24.6551\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.1462 - val_loss: 24.6371\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.0630 - val_loss: 24.6191\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 77.0044 - val_loss: 24.6012\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 77.0257 - val_loss: 24.5834\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 77.0670 - val_loss: 24.5656\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.8995 - val_loss: 24.5480\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.7256 - val_loss: 24.5305\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 76.8459 - val_loss: 24.5130\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 76.6461 - val_loss: 24.4958\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.6437 - val_loss: 24.4786\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 76.5617 - val_loss: 24.4614\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.4876 - val_loss: 24.4444\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.2764 - val_loss: 24.4275\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 76.3278 - val_loss: 24.4106\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.2457 - val_loss: 24.3938\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.3803 - val_loss: 24.3771\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.2251 - val_loss: 24.3604\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.0089 - val_loss: 24.3439\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.0203 - val_loss: 24.3275\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 75.9247 - val_loss: 24.3111\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 76.0070 - val_loss: 24.2947\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 76.0749 - val_loss: 24.2784\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.9924 - val_loss: 24.2622\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.7694 - val_loss: 24.2462\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.7319 - val_loss: 24.2301\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 75.8161 - val_loss: 24.2141\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.5464 - val_loss: 24.1984\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 75.7185 - val_loss: 24.1825\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.5471 - val_loss: 24.1668\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.4823 - val_loss: 24.1512\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.3712 - val_loss: 24.1356\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.1710 - val_loss: 24.1202\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.2958 - val_loss: 24.1047\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 75.2187 - val_loss: 24.0894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 75.0887 - val_loss: 24.0741\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.1886 - val_loss: 24.0588\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 75.0238 - val_loss: 24.0437\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.8965 - val_loss: 24.0285\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 75.0246 - val_loss: 24.0135\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 74.9558 - val_loss: 23.9985\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 74.8428 - val_loss: 23.9836\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.6471 - val_loss: 23.9688\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.8472 - val_loss: 23.9539\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 74.7829 - val_loss: 23.9392\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.7055 - val_loss: 23.9245\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.4852 - val_loss: 23.9099\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.5047 - val_loss: 23.8953\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.5437 - val_loss: 23.8808\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.5269 - val_loss: 23.8663\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.4692 - val_loss: 23.8519\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.3967 - val_loss: 23.8375\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.4759 - val_loss: 23.8231\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 74.2960 - val_loss: 23.8089\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 74.2528 - val_loss: 23.7947\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 74.0799 - val_loss: 23.7806\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 74.2123 - val_loss: 23.7665\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 74.1018 - val_loss: 23.7524\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 73.9400 - val_loss: 23.7385\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 74.0529 - val_loss: 23.7246\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 74.0606 - val_loss: 23.7106\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 73.8625 - val_loss: 23.6968\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.9992 - val_loss: 23.6830\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.8889 - val_loss: 23.6693\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.7797 - val_loss: 23.6556\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.7799 - val_loss: 23.6420\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.6703 - val_loss: 23.6284\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 73.5741 - val_loss: 23.6148\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.6563 - val_loss: 23.6013\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.4282 - val_loss: 23.5879\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.4581 - val_loss: 23.5745\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.5356 - val_loss: 23.5611\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.3495 - val_loss: 23.5478\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.3647 - val_loss: 23.5345\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.4692 - val_loss: 23.5212\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.2228 - val_loss: 23.5080\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.1095 - val_loss: 23.4949\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 73.2476 - val_loss: 23.4817\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 73.0074 - val_loss: 23.4686\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.9651 - val_loss: 23.4556\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.9955 - val_loss: 23.4426\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 73.0818 - val_loss: 23.4296\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 72.9380 - val_loss: 23.4166\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.9687 - val_loss: 23.4037\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 72.8313 - val_loss: 23.3909\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.7911 - val_loss: 23.3781\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 72.8177 - val_loss: 23.3653\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.6776 - val_loss: 23.3525\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.6564 - val_loss: 23.3398\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 72.5260 - val_loss: 23.3272\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.6867 - val_loss: 23.3145\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.4521 - val_loss: 23.3019\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.4780 - val_loss: 23.2893\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 72.3996 - val_loss: 23.2768\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.3954 - val_loss: 23.2643\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 72.4568 - val_loss: 23.2517\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.4070 - val_loss: 23.2392\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.2152 - val_loss: 23.2269\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.2206 - val_loss: 23.2145\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.2718 - val_loss: 23.2021\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.2518 - val_loss: 23.1897\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 72.0739 - val_loss: 23.1774\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 72.0908 - val_loss: 23.1652\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 72.0062 - val_loss: 23.1530\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 72.0691 - val_loss: 23.1407\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.8632 - val_loss: 23.1285\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.9967 - val_loss: 23.1163\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.9604 - val_loss: 23.1042\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.6983 - val_loss: 23.0921\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.7876 - val_loss: 23.0800\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.7579 - val_loss: 23.0679\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 71.7001 - val_loss: 23.0559\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.7358 - val_loss: 23.0439\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 71.6496 - val_loss: 23.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 71.7013 - val_loss: 23.0200\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.5643 - val_loss: 23.0080\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - ETA: 0s - loss: 75.67 - 0s 44us/step - loss: 71.5380 - val_loss: 22.9961\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.5552 - val_loss: 22.9842\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.4740 - val_loss: 22.9723\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.3738 - val_loss: 22.9605\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.4280 - val_loss: 22.9487\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 71.2908 - val_loss: 22.9369\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.2739 - val_loss: 22.9251\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.3470 - val_loss: 22.9133\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.2883 - val_loss: 22.9016\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.2292 - val_loss: 22.8899\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.1816 - val_loss: 22.8782\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.1092 - val_loss: 22.8665\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 71.0528 - val_loss: 22.8549\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.0136 - val_loss: 22.8433\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 71.0287 - val_loss: 22.8316\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 70.9023 - val_loss: 22.8201\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.9301 - val_loss: 22.8085\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.9022 - val_loss: 22.7969\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.8595 - val_loss: 22.7854\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.7799 - val_loss: 22.7739\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 70.7155 - val_loss: 22.7623\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 70.6488 - val_loss: 22.7509\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 70.6418 - val_loss: 22.7393\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 70.7138 - val_loss: 22.7279\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.6460 - val_loss: 22.7164\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 70.5537 - val_loss: 22.7050\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 70.4416 - val_loss: 22.6936\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 70.4821 - val_loss: 22.6822\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 70.4432 - val_loss: 22.6709\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.3399 - val_loss: 22.6595\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 70.4030 - val_loss: 22.6481\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 70.3217 - val_loss: 22.6368\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.3688 - val_loss: 22.6255\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.3232 - val_loss: 22.6141\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 70.1055 - val_loss: 22.6028\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 70.2374 - val_loss: 22.5916\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.1456 - val_loss: 22.5803\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.0582 - val_loss: 22.5690\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.0039 - val_loss: 22.5578\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 70.0509 - val_loss: 22.5465\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.9944 - val_loss: 22.5353\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 70.0276 - val_loss: 22.5241\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.9871 - val_loss: 22.5129\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 69.9120 - val_loss: 22.5016\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 69.8567 - val_loss: 22.4905\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 69.8773 - val_loss: 22.4793\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.8145 - val_loss: 22.4681\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.5786 - val_loss: 22.4570\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.7424 - val_loss: 22.4458\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 69.5786 - val_loss: 22.4347\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 69.7010 - val_loss: 22.4236\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.6333 - val_loss: 22.4124\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.5426 - val_loss: 22.4013\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 69.5298 - val_loss: 22.3902\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.4631 - val_loss: 22.3791\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 69.4654 - val_loss: 22.3680\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.4211 - val_loss: 22.3569\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 69.3062 - val_loss: 22.3459\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.3624 - val_loss: 22.3348\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.2977 - val_loss: 22.3237\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.2484 - val_loss: 22.3127\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.1563 - val_loss: 22.3016\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 69.1426 - val_loss: 22.2906\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 69.0774 - val_loss: 22.2795\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 69.0877 - val_loss: 22.2685\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.0691 - val_loss: 22.2574\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 69.0782 - val_loss: 22.2464\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.9044 - val_loss: 22.2354\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 68.9672 - val_loss: 22.2244\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.7516 - val_loss: 22.2134\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.9486 - val_loss: 22.2024\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 56us/step - loss: 68.8949 - val_loss: 22.1913\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.8816 - val_loss: 22.1803\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.8398 - val_loss: 22.1693\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.8226 - val_loss: 22.1583\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 68.6875 - val_loss: 22.1473\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.7629 - val_loss: 22.1363\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.6831 - val_loss: 22.1253\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.6507 - val_loss: 22.1143\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.6316 - val_loss: 22.1033\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.5638 - val_loss: 22.0923\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.4780 - val_loss: 22.0814\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.5541 - val_loss: 22.0704\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.4757 - val_loss: 22.0594\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.3528 - val_loss: 22.0484\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.3496 - val_loss: 22.0374\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.2923 - val_loss: 22.0264\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 68.3020 - val_loss: 22.0154\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 68.2206 - val_loss: 22.0045\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.1244 - val_loss: 21.9935\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.3375 - val_loss: 21.9825\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 68.1830 - val_loss: 21.9715\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 68.0480 - val_loss: 21.9605\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 67us/step - loss: 68.1119 - val_loss: 21.9495\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.1238 - val_loss: 21.9385\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 68.0558 - val_loss: 21.9275\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 67.9274 - val_loss: 21.9165\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 67.9662 - val_loss: 21.9055\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 67.9115 - val_loss: 21.8945\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 67.8032 - val_loss: 21.8835\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 67.7992 - val_loss: 21.8725\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 33us/step - loss: 67.7833 - val_loss: 21.8615\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 67.8078 - val_loss: 21.8504\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 67.6773 - val_loss: 21.8394\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 44us/step - loss: 67.7390 - val_loss: 21.8284\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train.reshape(-1,1), # pasamos el array como matriz\n",
    "                    np.repeat(y_train.reshape(-1,1), 2, axis = 1), # duplicamos las y-es para pasarlo a las  dos capas\n",
    "                    # aunque parece que no es obligatoria esta redimensión\n",
    "                    epochs = 500,\n",
    "                    validation_split = .1,\n",
    "                    verbose = 1\n",
    "                    \n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and visualize the results. Have we catched the heteroscedastic uncertainty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = np.arange(low,high,0.01).reshape(-1,1)\n",
    "y_test = f(X_test) + np.random.normal(\n",
    "    0,std,size=(X_test.shape[0])).reshape(-1,1)+[\n",
    "    np.random.normal(0,i) for i in (np.sin(X_test*-10))+1]\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "plt.errorbar(X_test,prediction[:,0],\n",
    "             yerr=2*prediction[:,1],\n",
    "             color='#0A5FB4',\n",
    "             alpha=0.8,\n",
    "             label='prediction')\n",
    "\n",
    "plt.plot(X_test, y_test,'x',c='r',\n",
    "         alpha=0.8, label='real generated data')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the Epistemic uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the *uncertainty quantification* field there is an approach that classifies uncertainty in two different categories:\n",
    "\n",
    "1. Aleatoric Uncertainty: If there exists a variability in our possible correct predictions for the same initial inputs (see previous section).\n",
    "\n",
    "2. Epistemic Uncertainty: related to our ignorance:\n",
    "\n",
    "     2.1. We are not using the correct model $\\phi_w$ to approximate the hyphothetical function $f$\n",
    "     \n",
    "     2.2. Our incomplete knowledge of the types of data that exists.\n",
    "\n",
    "There are different techniques in the literature for modeling the epistemic uncertainty. Here, we will cover the MCMC approach using tensorflow and the tensorflow_probability library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**. Consider a data set $\\{(\\mathbf{x}_n, y_n)\\}$, where each data point comprises of features $\\mathbf{x}_n\\in\\mathbb{R}^D$ and output $y_n\\in\\mathbb{R}$. Define the likelihood for each data point as $$\\begin{aligned} p(y_n \\mid \\mathbf{w}, \\mathbf{x}_n, \\sigma^2) &= \\text{Normal}(y_n \\mid \\mathrm{NN}(\\mathbf{x}_n\\;;\\;\\mathbf{w}), \\sigma^2),\\end{aligned}$$\n",
    "\n",
    "where $\\mathrm{NN}$ is a neural network whose weights and biases form the latent variables $\\mathbf{w}$. Assume $\\sigma^2$ is a known variance.\n",
    "\n",
    "Define the prior on the weights and biases $\\mathbf{w}$ to be the standard normal $$\\begin{aligned} p(\\mathbf{w}) &= \\text{Normal}(\\mathbf{w} \\mid \\mathbf{0}, \\mathbf{I}).\\end{aligned}$$\n",
    "\n",
    "The question here is: how these parameters (now random variables) are distributed (~posterior distribution)? Could you give an estimation of these variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solving the inference problem using MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noted in the introduction of this notebook, for most practical problems of interest exact inference is hard or can not be performed analytically. That is why some form of approximation need to be done. \n",
    "\n",
    "In this section we consider approximate inference methods based of numerical sampling to get the distribution of the latent variables.\n",
    "The main idea behing MCMC is to generate samples from the posterior distribution by constructing a reversible Markov-chain that has as its equilibrium distribution the target posterior distribution. In essence, MCMC will allow us finding the expectation of some function with repect to a probability distribution -- for instance, mean and variance of the latent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex. Using the Hamiltonian Monte Carlo `tfp.mcmc.HamiltonianMonteCarlo` method estimate the weights and biases of a linear regression problem.\n",
    "\n",
    "Use as data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_toy_dataset(N, w, noise_std=0.1):\n",
    "    x = np.random.randn(N)\n",
    "    y = x * w + np.random.normal(0, noise_std, size=N)\n",
    "    return x, y\n",
    "\n",
    "N = 40  # number of data points\n",
    "D = 1  # number of features\n",
    "\n",
    "w_true = np.random.randn()\n",
    "X_train, y_train = build_toy_dataset(N, w_true)\n",
    "X_test, y_test = build_toy_dataset(N, w_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import edward2 as ed\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "def linear_model(x_data=X_train):\n",
    "    A = ed.Normal(loc=0., scale=10., name=\"A\")  \n",
    "    b = ed.Normal(loc=0., scale=10., name=\"b\")  \n",
    "    mu = A * x_data + b\n",
    "    y_data = ed.Normal(loc=mu, scale=tf.ones(N), name=\"y_data\")  # `y` above\n",
    "    return y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the log-joint probability function using `ed.make_log_joint_fn`, and implements MCMC with the `tfp.mcmc.sample_chain` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the session, get the mean values of the weight and the bias and visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "[A_mcmc, b_mcmc] = sess.run([A, b])\n",
    "\n",
    "print(\"A Coefficient: \", A_mcmc.mean(), '+-', A_mcmc.var()  \n",
    "      , \"\\nb Coefficient: \", b_mcmc.mean(), '+-', b_mcmc.var() )\n",
    "\n",
    "def visualise(X_train, y_train, X_test, y_test, w, b, n_samples=10):\n",
    "    plt.scatter(X_train, y_train)\n",
    "    plt.scatter(X_test, y_test)\n",
    "    inputs = np.linspace(min(X_train.min(), X_test.min()),\n",
    "                         max(X_train.max(), X_test.max()), \n",
    "                         num=400)\n",
    "    for ns in range(n_samples):\n",
    "        #output = inputs * w[ns] + b[ns]\n",
    "        output = inputs * w.mean() + b.mean()\n",
    "        plt.plot(inputs, np.random.normal(output), 'r+')\n",
    "        \n",
    "visualise(X_train, y_train, X_test, y_test, A_mcmc, b_mcmc, n_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach for solving the inference problem at hand is the Variational inference one. In this approach, the density function is estimated by choosing a distribution we know (eg. Gaussian) and progressively changing its parameters via optimization until it looks like the one we want to compute, the posterior. \n",
    "This “made-up” distribution we are optimizing is called variational distribution. \n",
    "\n",
    "Ex. Derive mathematically the equivalence between choosing the optimal parameters for the variational distribution and maximizing a lower bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout (Hinton et al) is a technique used to avoid over-fitting in our model. In essence, dropout technique zeros out neurons randomly according to a Bernoulli distribution. \n",
    "\n",
    "In the context of Bayesian Deep Learning, dropout can be seen as a Gaussian process approximation. In order to get uncertainty estimates from dropout, we just have to apply it both when performing training and prediction steps.\n",
    "\n",
    "Predictive mean and variance can be obtained from the following equations:\n",
    "\n",
    "$$ \\mathbb{E}(y) \\sim \\frac{1}{T} \\sum_{t=0}^{t=T} \\hat{y}_t (x)$$\n",
    "\n",
    "$$ Var(y) \\sim \\tau^{-1} \\mathbb{I}_D + \\frac{1}{T} \\sum_{t=0}^{t=T} \\hat{y}_t (x)^T \\hat{y}_t (x) - \\mathbb{E}(y)^T\\mathbb{E}(y)$$\n",
    "\n",
    "where $\\hat{y}_t$ are the predictions and \n",
    "\n",
    "$$\\tau = \\frac{l^2 p}{2N\\lambda}$$\n",
    "\n",
    "summarizes our Gaussian process precision, with $l$ a prior length-scale that captures our belief over the function frequency, $p$ the probability of the units not being dropped, $N$ the number of points and $\\lambda$ the weight decay parameter.\n",
    "\n",
    "Let's see how to apply all these concepts taken our cosine regression problem (seen in the first classes of the course) as an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex: Implement $\\tau$ parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tau(l, p, N, weight_decay):\n",
    "    return l**2 * (1 - p) / (2 * N * weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "f = lambda x: np.cos(x)\n",
    "x_train = np.linspace(-2*np.pi, 1.5*np.pi,10000)\n",
    "y_train = f(x_train)\n",
    "\n",
    "x_test = np.linspace(1.505*np.pi,2.5*np.pi,50)\n",
    "y_test = f(x_test)\n",
    "\n",
    "x_train_norm = (x_train-x_train.mean())/(x_train.std())\n",
    "y_train_norm = (y_train-y_train.mean())/(y_train.std())\n",
    "\n",
    "plt.plot(x_train, y_train, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://arxiv.org/pdf/1601.00670.pdf\n",
    "\n",
    "http://bridg.land/posts/gaussian-processes-1\n",
    "\n",
    "https://arxiv.org/pdf/1703.04977.pdf\n",
    "\n",
    "https://medium.com/tensorflow/introducing-tensorflow-probability-dca4c304e245\n",
    "\n",
    "http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html\n",
    "\n",
    "https://medium.com/@joeDiHare/deep-bayesian-neural-networks-952763a9537\n",
    "\n",
    "http://pyro.ai/examples/bayesian_regression.html\n",
    "\n",
    "http://edwardlib.org/tutorials/supervised-regression\n",
    "\n",
    "https://docs.pymc.io/notebooks/bayesian_neural_network_advi.html\n",
    "\n",
    "https://github.com/arturzeitler/Bayes-and-MC/blob/master/Bayesian_NN_Example.ipynb\n",
    "\n",
    "https://arxiv.org/pdf/1610.09787.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_win)",
   "language": "python",
   "name": "dl_win"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
