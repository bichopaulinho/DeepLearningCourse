{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVwGV8AIQY9u"
   },
   "source": [
    "# CONTEXT BEFORE THE CHALLENGE\n",
    "\n",
    "This notebook contains a challenge and some exercises.\n",
    "\n",
    "The challenge is about creating an image classifier that can beat the rest of classifiers written by each student.\n",
    "\n",
    "All the data is ready and the notebook is prepared, so students only have to focus on choosing the best model and the best training hyperparameters.\n",
    "\n",
    "The notebook is using Python generators to traverse the data, due to its volume (it does not fit in memory). Because of this, some hyperparameters, such as batch size or data augmentation, are chosen in the data preparation section.\n",
    "\n",
    "## Data download\n",
    "This notebook can be used on Google Colab, or in a standalone way just using Jupyter. If you are using Jupyter, please download the original data manually, and ignore the cell where PyDrive downloads the data.\n",
    "\n",
    "The data is downloaded from https://drive.google.com/file/d/1c9va4iRjKZjbHTm_BMOKfbPERaxUKKsn/view?usp=sharing\n",
    "\n",
    "If you use Google Colab, you will need to authenticate to use PyDrive. Just follow the instructions in the cell that downloads the data.\n",
    "\n",
    "## Results upload\n",
    "The results are written in Pickle files. In the section **Share your predictions** you will find a cell to upload the results to Google Drive. If you are using Jupyter, you can upload your Pickle files manually to this folder:\n",
    "* https://drive.google.com/drive/folders/1_AEHONWOJotSVfn93mtXX5y8SpWi2Etw?usp=sharing\n",
    "\n",
    "## Cells to be changed by students\n",
    "\n",
    "Students need to change only the following cells:\n",
    "* In the **Data preparation** section, we choose the batch size, and parameters for data augmentation (if used). **Change those hyperparameters in these cells**.\n",
    "* In the **Challenge! Build the mest model you can!** section, you can define the architecture of your model, as well as the loss function, optimization method, etc. **Change your model and hyperparameters here**\n",
    "* In the **Evaluate model** you can check if your model is overfitting or underfitting. Use this section to decide how to change your model or hyperparameters, and to upload your results.\n",
    "* In the **Exercises** section, please try to solve all the exercises.\n",
    "\n",
    "## What about the rest of cells?\n",
    "\n",
    "This notebook is provided to make your life easier, so you can focus on trying to obtain the best model. Those cells just prepare the data for your model. So **our advice is not to touch those cells and focusing on your model and exercises**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeBZhwVOcX3Q"
   },
   "source": [
    "# Data preparation\n",
    "\n",
    "And some useful common code.\n",
    "\n",
    "Run these cells to get the data ready for your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qi9Xtusecslz"
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxZGrU_zcu-x"
   },
   "outputs": [],
   "source": [
    "def plot_metric(history, metric):\n",
    "    history_dict = history.history\n",
    "    values = history_dict[metric]\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        val_values = history_dict['val_' + metric]\n",
    "\n",
    "    epochs = range(1, len(values) + 1)\n",
    "\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        plt.plot(epochs, val_values, label='Validation')\n",
    "    plt.semilogy(epochs, values, label='Training')\n",
    "\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        plt.title('Training and validation %s' % metric)\n",
    "    else:\n",
    "        plt.title('Training %s' % metric)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VIhQIOFouZNJ"
   },
   "source": [
    "### Working from Local?\n",
    "\n",
    "If you are not using Google Colab, ignore this cell and download the data from this link:\n",
    "\n",
    "* https://drive.google.com/file/d/1c9va4iRjKZjbHTm_BMOKfbPERaxUKKsn/view?usp=sharing\n",
    "\n",
    "Put the ZIP file in the same directory as your notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGnorizfcxIE"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Download a file based on its file ID.\n",
    "#\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "file_id = '1c9va4iRjKZjbHTm_BMOKfbPERaxUKKsn'\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.GetContentFile(\"dogs_cats_small.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyWGBIq1dBB6"
   },
   "outputs": [],
   "source": [
    "# Continue from here even if you are running from local\n",
    "\n",
    "!rm -rf dogs_cats_small\n",
    "!unzip dogs_cats_small.zip > /dev/null\n",
    "!ls -hl dogs_cats_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l03Vxcg0dKg7"
   },
   "outputs": [],
   "source": [
    "# CHANGE THIS VARIABLE IF YOU ARE RUNNING FROM LOCAL\n",
    "BASE_PATH = \"/content\"  # /content for Google Colab, change if it is different in your case\n",
    "\n",
    "import os, shutil\n",
    "base_dir = \"%s/dogs_cats_small\" % BASE_PATH\n",
    "\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "test_dir = os.path.join(base_dir, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeI6JHYoiz_J"
   },
   "source": [
    "## Inspecting some data\n",
    "\n",
    "The training, validation and test sets are stored in different subdirectories.\n",
    "\n",
    "Each of those subdirs contains two subdirs, dogs and cats, for the images for each one of the labels.\n",
    "\n",
    "Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qz77KlPDjA0J"
   },
   "outputs": [],
   "source": [
    "print(\"This should be a dog:\")\n",
    "plt.imshow(mpl.image.imread('dogs_cats_small/train/dogs/dog.132.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCpjGZSvkX3b"
   },
   "outputs": [],
   "source": [
    "print(\"This should be a cat:\")\n",
    "plt.imshow(mpl.image.imread('dogs_cats_small/train/cats/cat.257.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8BNJx_DdnrP"
   },
   "source": [
    "# Choose your runtime\n",
    "\n",
    "You can try using a TPU or a GPU.\n",
    "\n",
    "If you are using a GPU, check that you have actually managed to grab one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIHk6WGseAtQ"
   },
   "outputs": [],
   "source": [
    "# Check if we have a GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()  # inspect output and try to find out if you have a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlt_lZ2YeBFk"
   },
   "source": [
    "# Data preparation\n",
    "\n",
    "The pictures are just too large to train all the dataset in memory. We need to use generators.\n",
    "\n",
    "**QUESTION**: We are rescaling the images. Why? Is it because we don't have enough memory and this will make the images smaller? What is the effect of rescaling the images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_eu9QjslzJF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oALMbFkCeWkp"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE=256  # Use with target size to make sure all imgs are of the same size\n",
    "              # The bigger the better, but memory is finite, so...\n",
    "\n",
    "# BEAR IN MIND THAT YOU ARE HERE SETTING THE BATCH SIZE\n",
    "# IF YOU NEED TO CHANGE IT, YOU HAVE TO CREATE THE GENERATORS AGAIN\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# You can also try to use *Data Augmentation* to get a better model\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1.0/255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=.2,\n",
    "#     height_shift_range=.2,\n",
    "#     shear_range=.2,\n",
    "#     zoom_range=.2,\n",
    "#     horizontal_flip=True\n",
    "# )\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vMTG1prskooI"
   },
   "source": [
    "# Challenge! Build model the best model you can!\n",
    "\n",
    "Here we build a simple model to illustrate how to train a model with generators.\n",
    "\n",
    "**CHALLENGE**: What's the best model you can find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkpFhwfzk3nr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6FNz0bnlhbm"
   },
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# =                                                 =\n",
    "# ------->   YOUR MODEL SHOULD GO HERE   <-----------\n",
    "# =                                                 =\n",
    "# ===================================================\n",
    "\n",
    "# If using CPUs or GPUs\n",
    "def build_model():\n",
    "  m = models.Sequential()\n",
    "  m.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "  m.add(layers.MaxPooling2D((2, 2)))\n",
    "  m.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "  m.add(layers.MaxPooling2D((2, 2)))\n",
    "  m.add(layers.Flatten())\n",
    "  m.add(layers.Dense(64, activation='relu'))\n",
    "  m.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOKSImjvljQk"
   },
   "outputs": [],
   "source": [
    "# If using TPUs\n",
    "def keras2tpu(m):\n",
    "  tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
    "    m,\n",
    "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
    "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])))\n",
    "\n",
    "  return tpu_model\n",
    "\n",
    "\n",
    "def build_model_tpu():\n",
    "  m = models.Sequential()\n",
    "  m.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "  m.add(layers.MaxPooling2D((2, 2)))    \n",
    "  m.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "  m.add(layers.MaxPooling2D((2, 2)))\n",
    "  m.add(layers.Flatten())\n",
    "  m.add(layers.Dense(256, activation='relu'))\n",
    "  m.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  return keras2tpu(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z98khkirtETv"
   },
   "outputs": [],
   "source": [
    "m = build_model()  # or m = build_model_tpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Po11-Iq-snko"
   },
   "outputs": [],
   "source": [
    "m.compile(loss=losses.binary_crossentropy, optimizer=tf.train.AdamOptimizer(), metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-FBGbqWtG9d"
   },
   "outputs": [],
   "source": [
    "h = m.fit_generator(train_generator, epochs=50, steps_per_epoch=10, validation_data=validation_generator, validation_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZyT4JOrtOxY"
   },
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4n_F0c1NteRu"
   },
   "outputs": [],
   "source": [
    "plot_metric(h, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tK6FCmQStj_J"
   },
   "outputs": [],
   "source": [
    "plot_metric(h, 'binary_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaNwgo1StmQc"
   },
   "outputs": [],
   "source": [
    "loss, acc = m.evaluate_generator(test_generator)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZl7dfkxtpWR"
   },
   "outputs": [],
   "source": [
    "predictions = m.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FarrJNW6CVYE"
   },
   "source": [
    "### Share your predictions\n",
    "\n",
    "To evaluate whether you have done better than others, we need your predictions\n",
    "\n",
    "Change the name of your team, serialize your predictions and upload to Google Drive.\n",
    "\n",
    "Please upload to this folder:\n",
    "* https://drive.google.com/drive/folders/1_AEHONWOJotSVfn93mtXX5y8SpWi2Etw?usp=sharing\n",
    "\n",
    "To upload, you can use this notebook from Colab, or you can do it manually from the web using the file that is generated in the next 2 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0-TEspHCfl_"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHVZc1mCDmK8"
   },
   "outputs": [],
   "source": [
    "YOUR_TEAM_NAME = \"The A team\"\n",
    "\n",
    "filename = \"%s_%s.pickle\" % (YOUR_TEAM_NAME, datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "# Serialize object\n",
    "pickle.dump(predictions, open(filename, 'wb'))\n",
    "\n",
    "print(\"Your participation in the challenge is recorded in the file\")\n",
    "print(\"\\n\\n   %s\\n\\n\" % filename)\n",
    "print(\"Please run the next cell in Google Colab to upload your file.\")\n",
    "print(\"Alternatively, please upload your file manually to this folder:\")\n",
    "print(\"https://drive.google.com/drive/folders/1_AEHONWOJotSVfn93mtXX5y8SpWi2Etw?usp=sharing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GA-4jIGJS8FH"
   },
   "outputs": [],
   "source": [
    "fid = \"1_AEHONWOJotSVfn93mtXX5y8SpWi2Etw\"  # don't change, this is the ID of the destination folder\n",
    "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
    "f.SetContentFile(filename)\n",
    "f.Upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoZ4CwI2xlyk"
   },
   "outputs": [],
   "source": [
    "test_labels = test_generator.classes.reshape((test_generator.n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0X3Gs6cxvRpg"
   },
   "outputs": [],
   "source": [
    "assert predictions.shape == test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Rv5waAiQO67"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GECHH52Ft19E"
   },
   "source": [
    "**EXERCISE** Can you construct the confusion matrix for this model? Can you calculate the precision and recall? How does it compare to accuracy?\n",
    "* See https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "\n",
    "**EXERCISE (more complex)** Keras decided some time ago to remove precision, recall and F1-score from the list of available metrics. Was it a good decision? Why? Why did the Keras' authors did not remove accuracy too?\n",
    "* https://github.com/keras-team/keras/issues/5794\n",
    "* https://github.com/keras-team/keras/issues/4592\n",
    "\n",
    "**EXERCISE** What is the ROC curve? Below we build the ROC curve for our model. How would you use a ROC curve to evaluate a classifier?\n",
    "* https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "* Help: https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idjMgAfhvLYt"
   },
   "outputs": [],
   "source": [
    "# Code to plot a ROC curve\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EabOeDYvOAv"
   },
   "outputs": [],
   "source": [
    "roc = metrics.roc_curve(test_labels, predictions)\n",
    "auc = metrics.roc_auc_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZeFMgP0Ahmo"
   },
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgWFcpZuAig_"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1], [0,1],'-')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RG2rD7v2RDwk"
   },
   "source": [
    "# INSTRUCTORS ONLY: GRAB ALL THE RESULTS FROM STUDENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2y9iURc6AlDq"
   },
   "outputs": [],
   "source": [
    "# STUDENTS: PLEASE IGNORE THIS CELL\n",
    "# This cell is only for the organizers to read all the data uploaded by the participants\n",
    "\n",
    "!mkdir -p team_results\n",
    "\n",
    "# Download all the participations\n",
    "fid = \"1_AEHONWOJotSVfn93mtXX5y8SpWi2Etw\"\n",
    "file_list = [(f['id'], f['originalFilename']) for f in drive.ListFile({'q': \"'%s' in parents and trashed=false\" % fid}).GetList()]\n",
    "\n",
    "for pickle_data in file_list:\n",
    "    pickle_id, pickle_fn = pickle_data\n",
    "    downloaded = drive.CreateFile({'id': pickle_id})\n",
    "    downloaded.GetContentFile(\"team_results/\" + pickle_fn)\n",
    "\n",
    "\n",
    "!ls -hl team_results\n",
    "\n",
    "# To read the serialized data\n",
    "# predictions = pickle.load(open('%s.pickle' % YOUR_TEAM_NAME, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Challenge: rastreator -- Create the best dog/cat classifier in the world!",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
