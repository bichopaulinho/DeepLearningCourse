{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "\n",
    "Input may optionally be reversed, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "Two digits reversed:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits reversed:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits reversed:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits reversed:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from six.moves import range\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "# config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "config = tf.ConfigProto(device_count = {'GPU': 1 , 'CPU': 8} ) \n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config) \n",
    "K.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable.encode(C='0 +', num_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ctable.encode(C='0 +', num_rows=5)\n",
    "ctable.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training(TRAINING_SIZE = 50000, DIGITS = 3, REVERSE = True):\n",
    "\n",
    "    # Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "    # int is DIGITS.\n",
    "    MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(questions) < TRAINING_SIZE:\n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b = f(), f()\n",
    "        # Skip any addition questions we've already seen\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "        key = tuple(sorted((a, b)))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        # Pad the data with spaces such that it is always MAXLEN.\n",
    "        q = '{}+{}'.format(a, b)\n",
    "        query = q + ' ' * (MAXLEN - len(q))\n",
    "        ans = str(a + b)\n",
    "        # Answers can be of maximum size DIGITS + 1.\n",
    "        ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "        if REVERSE:\n",
    "            # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "            # space used for padding.)\n",
    "            query = query[::-1]\n",
    "        questions.append(query)\n",
    "        answers.append(ans)\n",
    "    print('Total addition questions:', len(questions))\n",
    "    out = np.vstack((np.array(questions), np.array(answers)))\n",
    "    return out.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3char = generate_training(TRAINING_SIZE=50000, DIGITS=3, REVERSE=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(low=0, high=train3char.shape[0], size=4)\n",
    "train3char[r, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(train, DIGITS):\n",
    "    MAXLEN = 2*DIGITS+1\n",
    "    print('Vectorization...')\n",
    "    x = np.zeros((train.shape[0], MAXLEN, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((train.shape[0], DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "    # encode questions\n",
    "    for i, sentence in enumerate(train[:, 0]):\n",
    "        x[i] = ctable.encode(sentence, MAXLEN)\n",
    "    # encode answers\n",
    "    for i, sentence in enumerate(train[:, 1]):\n",
    "        y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "    # Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "    # digits.\n",
    "    indices = np.arange(len(y))\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    # Explicitly set apart 10% for validation data that we never train over.\n",
    "    split_at = len(x) - len(x) // 10\n",
    "    (x_train, x_val) = x[:split_at], x[split_at:]\n",
    "    (y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "    print('Shapes in training Data:')\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    print('Shapes in validation Data:')\n",
    "    print(x_val.shape)\n",
    "    print(y_val.shape)\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3char, y_train_3char, x_val_3char, y_val_3char = vectorization(train=train3char, DIGITS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(chars, rnn_type='gru', DIGITS=3, HIDDEN_SIZE=10, BATCH_SIZE=100, DECODER_LAYERS=1):\n",
    "    # ...\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3char = build_model(chars=chars, rnn_type='lstm', DIGITS=3, HIDDEN_SIZE=128, BATCH_SIZE=128, DECODER_LAYERS=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, x_val, y_val,  n_epochs=20, BATCH_SIZE=128, REVERSE=False):\n",
    "    # Train the model each generation and show predictions against the validation\n",
    "    # dataset.\n",
    "    for iteration in range(1, n_epochs+1):\n",
    "        # Train\n",
    "        # ...\n",
    "        \n",
    "        # Select 5 samples from the validation set at random so we can visualize\n",
    "        # errors.\n",
    "        for i in range(5):\n",
    "            # ...\n",
    "            print('Question: ', #....\n",
    "                 )\n",
    "            print('Answer: ', # ...\n",
    "                 )\n",
    "            if correct == guess:\n",
    "                print(colors.ok + '☑' + colors.close, end=' ')\n",
    "            else:\n",
    "                print(colors.fail + '☒' + colors.close, end=' ')\n",
    "            print('Guess: ', guess, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(model3char, x_train_3char, y_train_3char, x_val_3char, y_val_3char,  n_epochs=100, \n",
    "      BATCH_SIZE=128, REVERSE=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Five digits reversed:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ks_dl_course]",
   "language": "python",
   "name": "conda-env-ks_dl_course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
