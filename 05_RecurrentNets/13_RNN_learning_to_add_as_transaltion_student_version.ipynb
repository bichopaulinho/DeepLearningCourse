{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tbn1ypAGwJJe"
   },
   "source": [
    "# An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "\n",
    "Input may optionally be reversed, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "Two digits reversed:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits reversed:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits reversed:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits reversed:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxhYmlUbwJJg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from six.moves import range\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yk1X7dvCwJJj",
    "outputId": "5888add5-2a69-4400-9965-a636b8bb66aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "# config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "config = tf.ConfigProto(device_count = {'GPU': 1 , 'CPU': 8} ) \n",
    "config.gpu_options.allow_growth = True # toma memoria poco a poco según le haga falta\n",
    "\n",
    "sess = tf.Session(config=config) \n",
    "K.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlNkvnitwJJm"
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKFsrbOUwJJo"
   },
   "outputs": [],
   "source": [
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ ' # simple vocabulary\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "MG0ZgAUiwJJq",
    "outputId": "512fa61e-c862-4d80-8918-6c7db6fb914b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctable.encode(C='0 +', num_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "f6-UHVISwJJt",
    "outputId": "b9f53d46-9db5-4a01-d7d3-afdfa86fd0c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0 +  '"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ctable.encode(C='0 +', num_rows=5)\n",
    "print(x)\n",
    "ctable.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeyjcOBOwJJv"
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwU6DswtwJJx"
   },
   "outputs": [],
   "source": [
    "# generamos el dataset de preguntas y respuestas para un numero de digitos de sumando igual\n",
    "# cuidando que no se repitan preguntas\n",
    "def generate_training(TRAINING_SIZE = 50000, DIGITS = 3, REVERSE = True):\n",
    "\n",
    "    # Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "    # int is DIGITS.\n",
    "    MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(questions) < TRAINING_SIZE:\n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b = f(), f()\n",
    "        # Skip any addition questions we've already seen\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "        key = tuple(sorted((a, b))) # ordenamos para tener en cuenta la propiedad conmutativa de la suma\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        # Pad the data with spaces such that it is always MAXLEN.\n",
    "        q = '{}+{}'.format(a, b)\n",
    "        query = q + ' ' * (MAXLEN - len(q))\n",
    "        ans = str(a + b)\n",
    "        # Answers can be of maximum size DIGITS + 1.\n",
    "        ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "        if REVERSE:\n",
    "            # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "            # space used for padding.)\n",
    "            query = query[::-1]\n",
    "        questions.append(query)\n",
    "        answers.append(ans)\n",
    "    print('Total addition questions:', len(questions))\n",
    "    out = np.vstack((np.array(questions), np.array(answers)))\n",
    "    return out.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "9tuulnyB0s70",
    "outputId": "6a03bec4-a42e-4b05-dbd7-660d6752fe69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['6+9', '15'],\n",
       "       ['4+3', '7 '],\n",
       "       ['6+1', '7 '],\n",
       "       ['9+8', '17'],\n",
       "       ['8+4', '12']], dtype='<U3')"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_training(5,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "f2hPAQ8zwJJz",
    "outputId": "25a2c263-5b6a-4d51-80a4-00d5550c7387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "train3char = generate_training(TRAINING_SIZE=50000, DIGITS=3, REVERSE=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7-Z6lyK-wJJ2",
    "outputId": "c5b9a57d-265a-4fd9-be60-803b35c1bd10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "TagD9stNwJJ5",
    "outputId": "c79ec550-4ce0-4cd0-fb2b-a9277f39fcc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['525+841', '1366'],\n",
       "       ['816+883', '1699'],\n",
       "       ['17+5   ', '22  '],\n",
       "       ...,\n",
       "       ['210+943', '1153'],\n",
       "       ['40+995 ', '1035'],\n",
       "       ['278+85 ', '363 ']], dtype='<U7')"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "lSizuA54wJJ9",
    "outputId": "125eb094-7cf5-4f6f-c7e6-4f55664ca243"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['70+88  ', '158 '],\n",
       "       ['814+141', '955 '],\n",
       "       ['147+580', '727 '],\n",
       "       ['229+5  ', '234 ']], dtype='<U7')"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.random.randint(low=0, high=train3char.shape[0], size=4)\n",
    "train3char[r, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SHcfwExwJJ-"
   },
   "outputs": [],
   "source": [
    "# aplicamos one-hot\n",
    "def vectorization(train, DIGITS):\n",
    "    MAXLEN = 2*DIGITS+1\n",
    "    print('Vectorization...')\n",
    "    # samples, estados (long secuencia), dim embedding\n",
    "    x = np.zeros((train.shape[0], MAXLEN, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((train.shape[0], DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "    # encode questions\n",
    "    for i, sentence in enumerate(train[:, 0]):\n",
    "        x[i] = ctable.encode(sentence, MAXLEN)\n",
    "    # encode answers\n",
    "    for i, sentence in enumerate(train[:, 1]):\n",
    "        y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "    # Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "    # digits.\n",
    "    indices = np.arange(len(y))\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    # Explicitly set apart 10% for validation data that we never train over.\n",
    "    split_at = len(x) - len(x) // 10\n",
    "    (x_train, x_val) = x[:split_at], x[split_at:]\n",
    "    (y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "    print('Shapes in training Data:')\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    print('Shapes in validation Data:')\n",
    "    print(x_val.shape)\n",
    "    print(y_val.shape)\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "EFmM84VswJKB",
    "outputId": "a5a07379-6b02-470d-d316-0a1f38f163d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Shapes in training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Shapes in validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "x_train_3char, y_train_3char, x_val_3char, y_val_3char = vectorization(train=train3char, DIGITS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gug1cVLVwJKD"
   },
   "outputs": [],
   "source": [
    "def build_model(chars, rnn_type='gru', DIGITS=3, HIDDEN_SIZE=10, BATCH_SIZE=100, DECODER_LAYERS=1):\n",
    "    # ...\n",
    "    MAXLEN = 2*DIGITS + 1\n",
    "    \n",
    "    if rnn_type == 'gru':\n",
    "        RNN = layers.GRU\n",
    "    elif rnn_type == 'lstm':\n",
    "      RNN = layers.LSTM\n",
    "    elif rnn_type == 'rnn':\n",
    "      RNN = layers.simpleRNN\n",
    "    else:\n",
    "      sys.exit(-1)\n",
    "\n",
    "    \n",
    "    m = Sequential()\n",
    "    m.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars)))) \n",
    "    m.add(layers.RepeatVector(DIGITS + 1)) # replicamos la salida de la capa recurrente para meterla en el siguiente paso (decodificador), donde aprenderá la salida\n",
    "    #decoder\n",
    "    m.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "    # Aplicamos la misma capa densa a todos los estados de salida de la anterior\n",
    "    # Densa que saque la salida en forma de one-hot\n",
    "    m.add(layers.TimeDistributed(layers.Dense(len(chars), activation = 'softmax'))) # el tamaño de salida es el que necesita el decodificador\n",
    "    m.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "    m.summary()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "lU4DeuYpwJKF",
    "outputId": "ca9f84ae-9b6e-4e43-8366-054ed0ad7727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3char = build_model(chars=chars, rnn_type='lstm', DIGITS=3, HIDDEN_SIZE=128, BATCH_SIZE=128, DECODER_LAYERS=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TN5fUtRJwJKH"
   },
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, x_val, y_val,  n_epochs=20, BATCH_SIZE=128, REVERSE=False):\n",
    "    # Train the model each generation and show predictions against the validation\n",
    "    # dataset.\n",
    "    for iteration in range(1, n_epochs+1):\n",
    "        print()\n",
    "        print(\"-\"*50)\n",
    "        print(\"Iteration\", iteration)\n",
    "        \n",
    "        # Train\n",
    "        model.fit(x_train, y_train, epochs = 1, batch_size = 256, validation_data = (x_val, y_val))\n",
    "        \n",
    "        # Select 5 samples from the validation set at random so we can visualize\n",
    "        # errors.\n",
    "        idx_val = np.random.randint(0, len(x_val), 5)\n",
    "        pred = model.predict(x_val[idx_val])\n",
    "        for i in range(5):\n",
    "          #idx_val = np.array(np.random.randint(0, len(x_val)))\n",
    "          #print(idx_val, np.array(idx_val))\n",
    "          \n",
    "          \n",
    "          \n",
    "          \n",
    "          p = ctable.decode(x_val[idx_val[i]])\n",
    "          correct = ctable.decode(y_val[idx_val[i]])\n",
    "          guess = ctable.decode(pred[i])\n",
    "          \n",
    "          print('Question: ', p, 'Answer: ', correct)\n",
    "          \n",
    "          if correct == guess:\n",
    "              print(colors.ok + '☑' + colors.close, end=' ')\n",
    "          else:\n",
    "              print(colors.fail + '☒' + colors.close, end=' ')\n",
    "          print('Guess: ', guess, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 19991
    },
    "colab_type": "code",
    "id": "wjtnTN9fwJKJ",
    "outputId": "80389724-48f7-4eb5-cdd6-0d8b144f5916",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 140us/step - loss: 0.0156 - acc: 0.9986 - val_loss: 0.0302 - val_acc: 0.9915\n",
      "Question:  146+21  Answer:  167 \n",
      "\u001b[92m☑\u001b[0m Guess:  167 \n",
      "Question:  416+108 Answer:  524 \n",
      "\u001b[92m☑\u001b[0m Guess:  524 \n",
      "Question:  91+81   Answer:  172 \n",
      "\u001b[92m☑\u001b[0m Guess:  172 \n",
      "Question:  49+949  Answer:  998 \n",
      "\u001b[92m☑\u001b[0m Guess:  998 \n",
      "Question:  950+23  Answer:  973 \n",
      "\u001b[92m☑\u001b[0m Guess:  973 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0153 - acc: 0.9986 - val_loss: 0.0344 - val_acc: 0.9902\n",
      "Question:  48+860  Answer:  908 \n",
      "\u001b[92m☑\u001b[0m Guess:  908 \n",
      "Question:  170+277 Answer:  447 \n",
      "\u001b[92m☑\u001b[0m Guess:  447 \n",
      "Question:  826+7   Answer:  833 \n",
      "\u001b[92m☑\u001b[0m Guess:  833 \n",
      "Question:  45+154  Answer:  199 \n",
      "\u001b[91m☒\u001b[0m Guess:  299 \n",
      "Question:  15+48   Answer:  63  \n",
      "\u001b[92m☑\u001b[0m Guess:  63  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0388 - acc: 0.9892 - val_loss: 0.1443 - val_acc: 0.9488\n",
      "Question:  951+98  Answer:  1049\n",
      "\u001b[92m☑\u001b[0m Guess:  1049\n",
      "Question:  66+556  Answer:  622 \n",
      "\u001b[92m☑\u001b[0m Guess:  622 \n",
      "Question:  390+0   Answer:  390 \n",
      "\u001b[92m☑\u001b[0m Guess:  390 \n",
      "Question:  131+50  Answer:  181 \n",
      "\u001b[92m☑\u001b[0m Guess:  181 \n",
      "Question:  117+1   Answer:  118 \n",
      "\u001b[92m☑\u001b[0m Guess:  118 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0424 - acc: 0.9878 - val_loss: 0.0294 - val_acc: 0.9918\n",
      "Question:  960+12  Answer:  972 \n",
      "\u001b[92m☑\u001b[0m Guess:  972 \n",
      "Question:  669+422 Answer:  1091\n",
      "\u001b[92m☑\u001b[0m Guess:  1091\n",
      "Question:  64+52   Answer:  116 \n",
      "\u001b[92m☑\u001b[0m Guess:  116 \n",
      "Question:  324+48  Answer:  372 \n",
      "\u001b[92m☑\u001b[0m Guess:  372 \n",
      "Question:  16+770  Answer:  786 \n",
      "\u001b[92m☑\u001b[0m Guess:  786 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0140 - acc: 0.9986 - val_loss: 0.0264 - val_acc: 0.9925\n",
      "Question:  72+77   Answer:  149 \n",
      "\u001b[92m☑\u001b[0m Guess:  149 \n",
      "Question:  9+561   Answer:  570 \n",
      "\u001b[92m☑\u001b[0m Guess:  570 \n",
      "Question:  655+717 Answer:  1372\n",
      "\u001b[92m☑\u001b[0m Guess:  1372\n",
      "Question:  0+695   Answer:  695 \n",
      "\u001b[92m☑\u001b[0m Guess:  695 \n",
      "Question:  817+84  Answer:  901 \n",
      "\u001b[92m☑\u001b[0m Guess:  901 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0118 - acc: 0.9991 - val_loss: 0.0232 - val_acc: 0.9937\n",
      "Question:  731+442 Answer:  1173\n",
      "\u001b[92m☑\u001b[0m Guess:  1173\n",
      "Question:  721+428 Answer:  1149\n",
      "\u001b[92m☑\u001b[0m Guess:  1149\n",
      "Question:  3+409   Answer:  412 \n",
      "\u001b[92m☑\u001b[0m Guess:  412 \n",
      "Question:  581+20  Answer:  601 \n",
      "\u001b[92m☑\u001b[0m Guess:  601 \n",
      "Question:  2+816   Answer:  818 \n",
      "\u001b[92m☑\u001b[0m Guess:  818 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0111 - acc: 0.9992 - val_loss: 0.0236 - val_acc: 0.9935\n",
      "Question:  31+900  Answer:  931 \n",
      "\u001b[92m☑\u001b[0m Guess:  931 \n",
      "Question:  147+27  Answer:  174 \n",
      "\u001b[92m☑\u001b[0m Guess:  174 \n",
      "Question:  540+54  Answer:  594 \n",
      "\u001b[92m☑\u001b[0m Guess:  594 \n",
      "Question:  382+576 Answer:  958 \n",
      "\u001b[92m☑\u001b[0m Guess:  958 \n",
      "Question:  632+417 Answer:  1049\n",
      "\u001b[92m☑\u001b[0m Guess:  1049\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0222 - acc: 0.9947 - val_loss: 0.0543 - val_acc: 0.9820\n",
      "Question:  638+39  Answer:  677 \n",
      "\u001b[92m☑\u001b[0m Guess:  677 \n",
      "Question:  53+81   Answer:  134 \n",
      "\u001b[92m☑\u001b[0m Guess:  134 \n",
      "Question:  869+219 Answer:  1088\n",
      "\u001b[92m☑\u001b[0m Guess:  1088\n",
      "Question:  53+512  Answer:  565 \n",
      "\u001b[92m☑\u001b[0m Guess:  565 \n",
      "Question:  451+94  Answer:  545 \n",
      "\u001b[92m☑\u001b[0m Guess:  545 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0524 - acc: 0.9844 - val_loss: 0.0287 - val_acc: 0.9917\n",
      "Question:  609+20  Answer:  629 \n",
      "\u001b[92m☑\u001b[0m Guess:  629 \n",
      "Question:  783+662 Answer:  1445\n",
      "\u001b[92m☑\u001b[0m Guess:  1445\n",
      "Question:  84+327  Answer:  411 \n",
      "\u001b[92m☑\u001b[0m Guess:  411 \n",
      "Question:  819+50  Answer:  869 \n",
      "\u001b[92m☑\u001b[0m Guess:  869 \n",
      "Question:  749+696 Answer:  1445\n",
      "\u001b[92m☑\u001b[0m Guess:  1445\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0105 - acc: 0.9992 - val_loss: 0.0220 - val_acc: 0.9938\n",
      "Question:  980+842 Answer:  1822\n",
      "\u001b[92m☑\u001b[0m Guess:  1822\n",
      "Question:  216+339 Answer:  555 \n",
      "\u001b[92m☑\u001b[0m Guess:  555 \n",
      "Question:  162+755 Answer:  917 \n",
      "\u001b[92m☑\u001b[0m Guess:  917 \n",
      "Question:  31+298  Answer:  329 \n",
      "\u001b[92m☑\u001b[0m Guess:  329 \n",
      "Question:  76+159  Answer:  235 \n",
      "\u001b[92m☑\u001b[0m Guess:  235 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0090 - acc: 0.9996 - val_loss: 0.0224 - val_acc: 0.9935\n",
      "Question:  83+785  Answer:  868 \n",
      "\u001b[92m☑\u001b[0m Guess:  868 \n",
      "Question:  36+366  Answer:  402 \n",
      "\u001b[92m☑\u001b[0m Guess:  402 \n",
      "Question:  995+52  Answer:  1047\n",
      "\u001b[92m☑\u001b[0m Guess:  1047\n",
      "Question:  524+762 Answer:  1286\n",
      "\u001b[92m☑\u001b[0m Guess:  1286\n",
      "Question:  331+7   Answer:  338 \n",
      "\u001b[92m☑\u001b[0m Guess:  338 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0083 - acc: 0.9996 - val_loss: 0.0203 - val_acc: 0.9944\n",
      "Question:  889+8   Answer:  897 \n",
      "\u001b[92m☑\u001b[0m Guess:  897 \n",
      "Question:  594+283 Answer:  877 \n",
      "\u001b[92m☑\u001b[0m Guess:  877 \n",
      "Question:  453+1   Answer:  454 \n",
      "\u001b[92m☑\u001b[0m Guess:  454 \n",
      "Question:  875+77  Answer:  952 \n",
      "\u001b[92m☑\u001b[0m Guess:  952 \n",
      "Question:  865+386 Answer:  1251\n",
      "\u001b[92m☑\u001b[0m Guess:  1251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0085 - acc: 0.9993 - val_loss: 0.0218 - val_acc: 0.9935\n",
      "Question:  606+24  Answer:  630 \n",
      "\u001b[92m☑\u001b[0m Guess:  630 \n",
      "Question:  59+831  Answer:  890 \n",
      "\u001b[92m☑\u001b[0m Guess:  890 \n",
      "Question:  2+726   Answer:  728 \n",
      "\u001b[92m☑\u001b[0m Guess:  728 \n",
      "Question:  740+0   Answer:  740 \n",
      "\u001b[92m☑\u001b[0m Guess:  740 \n",
      "Question:  10+933  Answer:  943 \n",
      "\u001b[92m☑\u001b[0m Guess:  943 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0078 - acc: 0.9995 - val_loss: 0.0199 - val_acc: 0.9943\n",
      "Question:  69+396  Answer:  465 \n",
      "\u001b[92m☑\u001b[0m Guess:  465 \n",
      "Question:  93+285  Answer:  378 \n",
      "\u001b[92m☑\u001b[0m Guess:  378 \n",
      "Question:  886+897 Answer:  1783\n",
      "\u001b[92m☑\u001b[0m Guess:  1783\n",
      "Question:  24+856  Answer:  880 \n",
      "\u001b[92m☑\u001b[0m Guess:  880 \n",
      "Question:  93+970  Answer:  1063\n",
      "\u001b[92m☑\u001b[0m Guess:  1063\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0075 - acc: 0.9995 - val_loss: 0.0245 - val_acc: 0.9920\n",
      "Question:  29+820  Answer:  849 \n",
      "\u001b[92m☑\u001b[0m Guess:  849 \n",
      "Question:  0+997   Answer:  997 \n",
      "\u001b[91m☒\u001b[0m Guess:  996 \n",
      "Question:  72+506  Answer:  578 \n",
      "\u001b[92m☑\u001b[0m Guess:  578 \n",
      "Question:  383+75  Answer:  458 \n",
      "\u001b[92m☑\u001b[0m Guess:  458 \n",
      "Question:  351+847 Answer:  1198\n",
      "\u001b[92m☑\u001b[0m Guess:  1198\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0506 - acc: 0.9838 - val_loss: 0.1393 - val_acc: 0.9543\n",
      "Question:  509+721 Answer:  1230\n",
      "\u001b[92m☑\u001b[0m Guess:  1230\n",
      "Question:  815+47  Answer:  862 \n",
      "\u001b[92m☑\u001b[0m Guess:  862 \n",
      "Question:  527+195 Answer:  722 \n",
      "\u001b[92m☑\u001b[0m Guess:  722 \n",
      "Question:  754+769 Answer:  1523\n",
      "\u001b[92m☑\u001b[0m Guess:  1523\n",
      "Question:  11+42   Answer:  53  \n",
      "\u001b[92m☑\u001b[0m Guess:  53  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0269 - acc: 0.9926 - val_loss: 0.0211 - val_acc: 0.9938\n",
      "Question:  1+364   Answer:  365 \n",
      "\u001b[92m☑\u001b[0m Guess:  365 \n",
      "Question:  98+354  Answer:  452 \n",
      "\u001b[92m☑\u001b[0m Guess:  452 \n",
      "Question:  38+438  Answer:  476 \n",
      "\u001b[92m☑\u001b[0m Guess:  476 \n",
      "Question:  103+282 Answer:  385 \n",
      "\u001b[92m☑\u001b[0m Guess:  385 \n",
      "Question:  214+573 Answer:  787 \n",
      "\u001b[92m☑\u001b[0m Guess:  787 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.0190 - val_acc: 0.9949\n",
      "Question:  212+533 Answer:  745 \n",
      "\u001b[92m☑\u001b[0m Guess:  745 \n",
      "Question:  80+435  Answer:  515 \n",
      "\u001b[92m☑\u001b[0m Guess:  515 \n",
      "Question:  982+732 Answer:  1714\n",
      "\u001b[92m☑\u001b[0m Guess:  1714\n",
      "Question:  186+7   Answer:  193 \n",
      "\u001b[92m☑\u001b[0m Guess:  193 \n",
      "Question:  646+916 Answer:  1562\n",
      "\u001b[92m☑\u001b[0m Guess:  1562\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0065 - acc: 0.9996 - val_loss: 0.0196 - val_acc: 0.9943\n",
      "Question:  4+706   Answer:  710 \n",
      "\u001b[92m☑\u001b[0m Guess:  710 \n",
      "Question:  527+520 Answer:  1047\n",
      "\u001b[92m☑\u001b[0m Guess:  1047\n",
      "Question:  35+19   Answer:  54  \n",
      "\u001b[92m☑\u001b[0m Guess:  54  \n",
      "Question:  32+802  Answer:  834 \n",
      "\u001b[92m☑\u001b[0m Guess:  834 \n",
      "Question:  460+85  Answer:  545 \n",
      "\u001b[92m☑\u001b[0m Guess:  545 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0061 - acc: 0.9996 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Question:  948+85  Answer:  1033\n",
      "\u001b[92m☑\u001b[0m Guess:  1033\n",
      "Question:  342+696 Answer:  1038\n",
      "\u001b[92m☑\u001b[0m Guess:  1038\n",
      "Question:  808+498 Answer:  1306\n",
      "\u001b[92m☑\u001b[0m Guess:  1306\n",
      "Question:  10+263  Answer:  273 \n",
      "\u001b[92m☑\u001b[0m Guess:  273 \n",
      "Question:  5+960   Answer:  965 \n",
      "\u001b[92m☑\u001b[0m Guess:  965 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0059 - acc: 0.9996 - val_loss: 0.0220 - val_acc: 0.9929\n",
      "Question:  37+63   Answer:  100 \n",
      "\u001b[91m☒\u001b[0m Guess:  900 \n",
      "Question:  18+831  Answer:  849 \n",
      "\u001b[92m☑\u001b[0m Guess:  849 \n",
      "Question:  207+170 Answer:  377 \n",
      "\u001b[92m☑\u001b[0m Guess:  377 \n",
      "Question:  53+654  Answer:  707 \n",
      "\u001b[92m☑\u001b[0m Guess:  707 \n",
      "Question:  444+36  Answer:  480 \n",
      "\u001b[92m☑\u001b[0m Guess:  480 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 0.0169 - val_acc: 0.9953\n",
      "Question:  125+686 Answer:  811 \n",
      "\u001b[92m☑\u001b[0m Guess:  811 \n",
      "Question:  34+20   Answer:  54  \n",
      "\u001b[92m☑\u001b[0m Guess:  54  \n",
      "Question:  99+55   Answer:  154 \n",
      "\u001b[92m☑\u001b[0m Guess:  154 \n",
      "Question:  948+46  Answer:  994 \n",
      "\u001b[92m☑\u001b[0m Guess:  994 \n",
      "Question:  926+26  Answer:  952 \n",
      "\u001b[92m☑\u001b[0m Guess:  952 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0212 - val_acc: 0.9930\n",
      "Question:  97+670  Answer:  767 \n",
      "\u001b[92m☑\u001b[0m Guess:  767 \n",
      "Question:  75+31   Answer:  106 \n",
      "\u001b[92m☑\u001b[0m Guess:  106 \n",
      "Question:  56+279  Answer:  335 \n",
      "\u001b[92m☑\u001b[0m Guess:  335 \n",
      "Question:  915+690 Answer:  1605\n",
      "\u001b[91m☒\u001b[0m Guess:  1695\n",
      "Question:  52+792  Answer:  844 \n",
      "\u001b[92m☑\u001b[0m Guess:  844 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0072 - acc: 0.9990 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Question:  25+123  Answer:  148 \n",
      "\u001b[92m☑\u001b[0m Guess:  148 \n",
      "Question:  501+20  Answer:  521 \n",
      "\u001b[92m☑\u001b[0m Guess:  521 \n",
      "Question:  617+28  Answer:  645 \n",
      "\u001b[92m☑\u001b[0m Guess:  645 \n",
      "Question:  33+82   Answer:  115 \n",
      "\u001b[92m☑\u001b[0m Guess:  115 \n",
      "Question:  11+164  Answer:  175 \n",
      "\u001b[92m☑\u001b[0m Guess:  175 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0529 - acc: 0.9839 - val_loss: 0.0274 - val_acc: 0.9912\n",
      "Question:  786+9   Answer:  795 \n",
      "\u001b[92m☑\u001b[0m Guess:  795 \n",
      "Question:  915+96  Answer:  1011\n",
      "\u001b[92m☑\u001b[0m Guess:  1011\n",
      "Question:  393+88  Answer:  481 \n",
      "\u001b[92m☑\u001b[0m Guess:  481 \n",
      "Question:  99+783  Answer:  882 \n",
      "\u001b[92m☑\u001b[0m Guess:  882 \n",
      "Question:  61+757  Answer:  818 \n",
      "\u001b[92m☑\u001b[0m Guess:  818 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0075 - acc: 0.9992 - val_loss: 0.0163 - val_acc: 0.9953\n",
      "Question:  80+424  Answer:  504 \n",
      "\u001b[92m☑\u001b[0m Guess:  504 \n",
      "Question:  660+25  Answer:  685 \n",
      "\u001b[92m☑\u001b[0m Guess:  685 \n",
      "Question:  368+6   Answer:  374 \n",
      "\u001b[92m☑\u001b[0m Guess:  374 \n",
      "Question:  817+517 Answer:  1334\n",
      "\u001b[92m☑\u001b[0m Guess:  1334\n",
      "Question:  417+82  Answer:  499 \n",
      "\u001b[92m☑\u001b[0m Guess:  499 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0050 - acc: 0.9998 - val_loss: 0.0160 - val_acc: 0.9956\n",
      "Question:  273+49  Answer:  322 \n",
      "\u001b[92m☑\u001b[0m Guess:  322 \n",
      "Question:  817+62  Answer:  879 \n",
      "\u001b[92m☑\u001b[0m Guess:  879 \n",
      "Question:  64+344  Answer:  408 \n",
      "\u001b[92m☑\u001b[0m Guess:  408 \n",
      "Question:  32+38   Answer:  70  \n",
      "\u001b[92m☑\u001b[0m Guess:  70  \n",
      "Question:  554+20  Answer:  574 \n",
      "\u001b[92m☑\u001b[0m Guess:  574 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0044 - acc: 0.9998 - val_loss: 0.0148 - val_acc: 0.9959\n",
      "Question:  252+291 Answer:  543 \n",
      "\u001b[92m☑\u001b[0m Guess:  543 \n",
      "Question:  398+73  Answer:  471 \n",
      "\u001b[92m☑\u001b[0m Guess:  471 \n",
      "Question:  748+4   Answer:  752 \n",
      "\u001b[92m☑\u001b[0m Guess:  752 \n",
      "Question:  18+80   Answer:  98  \n",
      "\u001b[92m☑\u001b[0m Guess:  98  \n",
      "Question:  983+8   Answer:  991 \n",
      "\u001b[92m☑\u001b[0m Guess:  991 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0042 - acc: 0.9998 - val_loss: 0.0146 - val_acc: 0.9957\n",
      "Question:  958+20  Answer:  978 \n",
      "\u001b[92m☑\u001b[0m Guess:  978 \n",
      "Question:  50+35   Answer:  85  \n",
      "\u001b[92m☑\u001b[0m Guess:  85  \n",
      "Question:  33+349  Answer:  382 \n",
      "\u001b[92m☑\u001b[0m Guess:  382 \n",
      "Question:  175+292 Answer:  467 \n",
      "\u001b[92m☑\u001b[0m Guess:  467 \n",
      "Question:  34+322  Answer:  356 \n",
      "\u001b[92m☑\u001b[0m Guess:  356 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.0142 - val_acc: 0.9957\n",
      "Question:  6+766   Answer:  772 \n",
      "\u001b[92m☑\u001b[0m Guess:  772 \n",
      "Question:  286+2   Answer:  288 \n",
      "\u001b[92m☑\u001b[0m Guess:  288 \n",
      "Question:  2+358   Answer:  360 \n",
      "\u001b[92m☑\u001b[0m Guess:  360 \n",
      "Question:  348+34  Answer:  382 \n",
      "\u001b[92m☑\u001b[0m Guess:  382 \n",
      "Question:  70+33   Answer:  103 \n",
      "\u001b[92m☑\u001b[0m Guess:  103 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0039 - acc: 0.9998 - val_loss: 0.0137 - val_acc: 0.9962\n",
      "Question:  181+23  Answer:  204 \n",
      "\u001b[92m☑\u001b[0m Guess:  204 \n",
      "Question:  891+81  Answer:  972 \n",
      "\u001b[92m☑\u001b[0m Guess:  972 \n",
      "Question:  591+93  Answer:  684 \n",
      "\u001b[92m☑\u001b[0m Guess:  684 \n",
      "Question:  903+6   Answer:  909 \n",
      "\u001b[91m☒\u001b[0m Guess:  919 \n",
      "Question:  180+564 Answer:  744 \n",
      "\u001b[92m☑\u001b[0m Guess:  744 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0038 - acc: 0.9998 - val_loss: 0.0169 - val_acc: 0.9944\n",
      "Question:  63+235  Answer:  298 \n",
      "\u001b[92m☑\u001b[0m Guess:  298 \n",
      "Question:  9+574   Answer:  583 \n",
      "\u001b[92m☑\u001b[0m Guess:  583 \n",
      "Question:  30+338  Answer:  368 \n",
      "\u001b[92m☑\u001b[0m Guess:  368 \n",
      "Question:  1+300   Answer:  301 \n",
      "\u001b[92m☑\u001b[0m Guess:  301 \n",
      "Question:  562+7   Answer:  569 \n",
      "\u001b[92m☑\u001b[0m Guess:  569 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0487 - val_acc: 0.9865\n",
      "Question:  41+344  Answer:  385 \n",
      "\u001b[92m☑\u001b[0m Guess:  385 \n",
      "Question:  407+388 Answer:  795 \n",
      "\u001b[92m☑\u001b[0m Guess:  795 \n",
      "Question:  30+338  Answer:  368 \n",
      "\u001b[92m☑\u001b[0m Guess:  368 \n",
      "Question:  692+906 Answer:  1598\n",
      "\u001b[91m☒\u001b[0m Guess:  1698\n",
      "Question:  975+317 Answer:  1292\n",
      "\u001b[92m☑\u001b[0m Guess:  1292\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 144us/step - loss: 0.0928 - acc: 0.9712 - val_loss: 0.0577 - val_acc: 0.9796\n",
      "Question:  406+888 Answer:  1294\n",
      "\u001b[91m☒\u001b[0m Guess:  1295\n",
      "Question:  134+299 Answer:  433 \n",
      "\u001b[92m☑\u001b[0m Guess:  433 \n",
      "Question:  733+532 Answer:  1265\n",
      "\u001b[92m☑\u001b[0m Guess:  1265\n",
      "Question:  4+506   Answer:  510 \n",
      "\u001b[92m☑\u001b[0m Guess:  510 \n",
      "Question:  177+4   Answer:  181 \n",
      "\u001b[92m☑\u001b[0m Guess:  181 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0104 - acc: 0.9981 - val_loss: 0.0159 - val_acc: 0.9955\n",
      "Question:  501+61  Answer:  562 \n",
      "\u001b[92m☑\u001b[0m Guess:  562 \n",
      "Question:  53+961  Answer:  1014\n",
      "\u001b[92m☑\u001b[0m Guess:  1014\n",
      "Question:  789+6   Answer:  795 \n",
      "\u001b[92m☑\u001b[0m Guess:  795 \n",
      "Question:  47+760  Answer:  807 \n",
      "\u001b[92m☑\u001b[0m Guess:  807 \n",
      "Question:  478+152 Answer:  630 \n",
      "\u001b[92m☑\u001b[0m Guess:  630 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.0136 - val_acc: 0.9963\n",
      "Question:  173+111 Answer:  284 \n",
      "\u001b[92m☑\u001b[0m Guess:  284 \n",
      "Question:  470+7   Answer:  477 \n",
      "\u001b[92m☑\u001b[0m Guess:  477 \n",
      "Question:  398+52  Answer:  450 \n",
      "\u001b[92m☑\u001b[0m Guess:  450 \n",
      "Question:  98+212  Answer:  310 \n",
      "\u001b[92m☑\u001b[0m Guess:  310 \n",
      "Question:  5+912   Answer:  917 \n",
      "\u001b[92m☑\u001b[0m Guess:  917 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 144us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 0.0140 - val_acc: 0.9959\n",
      "Question:  184+80  Answer:  264 \n",
      "\u001b[92m☑\u001b[0m Guess:  264 \n",
      "Question:  186+7   Answer:  193 \n",
      "\u001b[92m☑\u001b[0m Guess:  193 \n",
      "Question:  24+87   Answer:  111 \n",
      "\u001b[92m☑\u001b[0m Guess:  111 \n",
      "Question:  0+711   Answer:  711 \n",
      "\u001b[92m☑\u001b[0m Guess:  711 \n",
      "Question:  583+42  Answer:  625 \n",
      "\u001b[92m☑\u001b[0m Guess:  625 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0034 - acc: 0.9999 - val_loss: 0.0127 - val_acc: 0.9965\n",
      "Question:  948+5   Answer:  953 \n",
      "\u001b[92m☑\u001b[0m Guess:  953 \n",
      "Question:  813+72  Answer:  885 \n",
      "\u001b[92m☑\u001b[0m Guess:  885 \n",
      "Question:  363+36  Answer:  399 \n",
      "\u001b[92m☑\u001b[0m Guess:  399 \n",
      "Question:  419+5   Answer:  424 \n",
      "\u001b[92m☑\u001b[0m Guess:  424 \n",
      "Question:  884+91  Answer:  975 \n",
      "\u001b[92m☑\u001b[0m Guess:  975 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0033 - acc: 0.9999 - val_loss: 0.0141 - val_acc: 0.9952\n",
      "Question:  999+618 Answer:  1617\n",
      "\u001b[92m☑\u001b[0m Guess:  1617\n",
      "Question:  22+910  Answer:  932 \n",
      "\u001b[92m☑\u001b[0m Guess:  932 \n",
      "Question:  47+688  Answer:  735 \n",
      "\u001b[92m☑\u001b[0m Guess:  735 \n",
      "Question:  957+276 Answer:  1233\n",
      "\u001b[92m☑\u001b[0m Guess:  1233\n",
      "Question:  8+634   Answer:  642 \n",
      "\u001b[92m☑\u001b[0m Guess:  642 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0031 - acc: 0.9999 - val_loss: 0.0129 - val_acc: 0.9960\n",
      "Question:  28+940  Answer:  968 \n",
      "\u001b[92m☑\u001b[0m Guess:  968 \n",
      "Question:  478+66  Answer:  544 \n",
      "\u001b[92m☑\u001b[0m Guess:  544 \n",
      "Question:  459+69  Answer:  528 \n",
      "\u001b[92m☑\u001b[0m Guess:  528 \n",
      "Question:  305+378 Answer:  683 \n",
      "\u001b[92m☑\u001b[0m Guess:  683 \n",
      "Question:  564+52  Answer:  616 \n",
      "\u001b[92m☑\u001b[0m Guess:  616 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 141us/step - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0121 - val_acc: 0.9966\n",
      "Question:  8+334   Answer:  342 \n",
      "\u001b[92m☑\u001b[0m Guess:  342 \n",
      "Question:  455+846 Answer:  1301\n",
      "\u001b[92m☑\u001b[0m Guess:  1301\n",
      "Question:  4+67    Answer:  71  \n",
      "\u001b[92m☑\u001b[0m Guess:  71  \n",
      "Question:  460+85  Answer:  545 \n",
      "\u001b[92m☑\u001b[0m Guess:  545 \n",
      "Question:  695+440 Answer:  1135\n",
      "\u001b[92m☑\u001b[0m Guess:  1135\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 141us/step - loss: 0.0028 - acc: 0.9999 - val_loss: 0.0128 - val_acc: 0.9961\n",
      "Question:  529+182 Answer:  711 \n",
      "\u001b[92m☑\u001b[0m Guess:  711 \n",
      "Question:  9+599   Answer:  608 \n",
      "\u001b[92m☑\u001b[0m Guess:  608 \n",
      "Question:  680+58  Answer:  738 \n",
      "\u001b[92m☑\u001b[0m Guess:  738 \n",
      "Question:  7+520   Answer:  527 \n",
      "\u001b[92m☑\u001b[0m Guess:  527 \n",
      "Question:  70+947  Answer:  1017\n",
      "\u001b[92m☑\u001b[0m Guess:  1017\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.0126 - val_acc: 0.9963\n",
      "Question:  347+94  Answer:  441 \n",
      "\u001b[92m☑\u001b[0m Guess:  441 \n",
      "Question:  83+359  Answer:  442 \n",
      "\u001b[92m☑\u001b[0m Guess:  442 \n",
      "Question:  373+349 Answer:  722 \n",
      "\u001b[92m☑\u001b[0m Guess:  722 \n",
      "Question:  747+86  Answer:  833 \n",
      "\u001b[92m☑\u001b[0m Guess:  833 \n",
      "Question:  18+45   Answer:  63  \n",
      "\u001b[92m☑\u001b[0m Guess:  63  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0143 - val_acc: 0.9956\n",
      "Question:  109+206 Answer:  315 \n",
      "\u001b[92m☑\u001b[0m Guess:  315 \n",
      "Question:  781+0   Answer:  781 \n",
      "\u001b[92m☑\u001b[0m Guess:  781 \n",
      "Question:  56+255  Answer:  311 \n",
      "\u001b[92m☑\u001b[0m Guess:  311 \n",
      "Question:  77+197  Answer:  274 \n",
      "\u001b[92m☑\u001b[0m Guess:  274 \n",
      "Question:  265+98  Answer:  363 \n",
      "\u001b[92m☑\u001b[0m Guess:  363 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0496 - acc: 0.9848 - val_loss: 0.0964 - val_acc: 0.9663\n",
      "Question:  272+2   Answer:  274 \n",
      "\u001b[92m☑\u001b[0m Guess:  274 \n",
      "Question:  8+595   Answer:  603 \n",
      "\u001b[92m☑\u001b[0m Guess:  603 \n",
      "Question:  12+80   Answer:  92  \n",
      "\u001b[91m☒\u001b[0m Guess:  91  \n",
      "Question:  7+156   Answer:  163 \n",
      "\u001b[92m☑\u001b[0m Guess:  163 \n",
      "Question:  470+3   Answer:  473 \n",
      "\u001b[92m☑\u001b[0m Guess:  473 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 141us/step - loss: 0.0212 - acc: 0.9939 - val_loss: 0.0155 - val_acc: 0.9953\n",
      "Question:  261+0   Answer:  261 \n",
      "\u001b[92m☑\u001b[0m Guess:  261 \n",
      "Question:  973+1   Answer:  974 \n",
      "\u001b[92m☑\u001b[0m Guess:  974 \n",
      "Question:  241+837 Answer:  1078\n",
      "\u001b[92m☑\u001b[0m Guess:  1078\n",
      "Question:  900+5   Answer:  905 \n",
      "\u001b[92m☑\u001b[0m Guess:  905 \n",
      "Question:  129+46  Answer:  175 \n",
      "\u001b[92m☑\u001b[0m Guess:  175 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 144us/step - loss: 0.0039 - acc: 0.9998 - val_loss: 0.0131 - val_acc: 0.9964\n",
      "Question:  199+1   Answer:  200 \n",
      "\u001b[92m☑\u001b[0m Guess:  200 \n",
      "Question:  77+738  Answer:  815 \n",
      "\u001b[92m☑\u001b[0m Guess:  815 \n",
      "Question:  62+576  Answer:  638 \n",
      "\u001b[92m☑\u001b[0m Guess:  638 \n",
      "Question:  498+94  Answer:  592 \n",
      "\u001b[92m☑\u001b[0m Guess:  592 \n",
      "Question:  19+458  Answer:  477 \n",
      "\u001b[92m☑\u001b[0m Guess:  477 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9965\n",
      "Question:  691+8   Answer:  699 \n",
      "\u001b[92m☑\u001b[0m Guess:  699 \n",
      "Question:  18+129  Answer:  147 \n",
      "\u001b[92m☑\u001b[0m Guess:  147 \n",
      "Question:  91+75   Answer:  166 \n",
      "\u001b[92m☑\u001b[0m Guess:  166 \n",
      "Question:  21+234  Answer:  255 \n",
      "\u001b[92m☑\u001b[0m Guess:  255 \n",
      "Question:  666+68  Answer:  734 \n",
      "\u001b[92m☑\u001b[0m Guess:  734 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 141us/step - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0114 - val_acc: 0.9969\n",
      "Question:  367+502 Answer:  869 \n",
      "\u001b[92m☑\u001b[0m Guess:  869 \n",
      "Question:  27+1    Answer:  28  \n",
      "\u001b[92m☑\u001b[0m Guess:  28  \n",
      "Question:  93+37   Answer:  130 \n",
      "\u001b[92m☑\u001b[0m Guess:  130 \n",
      "Question:  726+87  Answer:  813 \n",
      "\u001b[92m☑\u001b[0m Guess:  813 \n",
      "Question:  614+29  Answer:  643 \n",
      "\u001b[92m☑\u001b[0m Guess:  643 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0114 - val_acc: 0.9964\n",
      "Question:  313+22  Answer:  335 \n",
      "\u001b[92m☑\u001b[0m Guess:  335 \n",
      "Question:  9+25    Answer:  34  \n",
      "\u001b[92m☑\u001b[0m Guess:  34  \n",
      "Question:  59+955  Answer:  1014\n",
      "\u001b[92m☑\u001b[0m Guess:  1014\n",
      "Question:  12+21   Answer:  33  \n",
      "\u001b[92m☑\u001b[0m Guess:  33  \n",
      "Question:  57+810  Answer:  867 \n",
      "\u001b[92m☑\u001b[0m Guess:  867 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9968\n",
      "Question:  69+994  Answer:  1063\n",
      "\u001b[92m☑\u001b[0m Guess:  1063\n",
      "Question:  31+269  Answer:  300 \n",
      "\u001b[92m☑\u001b[0m Guess:  300 \n",
      "Question:  920+2   Answer:  922 \n",
      "\u001b[92m☑\u001b[0m Guess:  922 \n",
      "Question:  59+831  Answer:  890 \n",
      "\u001b[92m☑\u001b[0m Guess:  890 \n",
      "Question:  31+91   Answer:  122 \n",
      "\u001b[92m☑\u001b[0m Guess:  122 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0122 - val_acc: 0.9961\n",
      "Question:  5+764   Answer:  769 \n",
      "\u001b[92m☑\u001b[0m Guess:  769 \n",
      "Question:  16+201  Answer:  217 \n",
      "\u001b[92m☑\u001b[0m Guess:  217 \n",
      "Question:  422+88  Answer:  510 \n",
      "\u001b[92m☑\u001b[0m Guess:  510 \n",
      "Question:  202+438 Answer:  640 \n",
      "\u001b[92m☑\u001b[0m Guess:  640 \n",
      "Question:  53+83   Answer:  136 \n",
      "\u001b[92m☑\u001b[0m Guess:  136 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 145us/step - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0126 - val_acc: 0.9962\n",
      "Question:  108+97  Answer:  205 \n",
      "\u001b[92m☑\u001b[0m Guess:  205 \n",
      "Question:  329+532 Answer:  861 \n",
      "\u001b[92m☑\u001b[0m Guess:  861 \n",
      "Question:  44+739  Answer:  783 \n",
      "\u001b[92m☑\u001b[0m Guess:  783 \n",
      "Question:  91+332  Answer:  423 \n",
      "\u001b[92m☑\u001b[0m Guess:  423 \n",
      "Question:  38+79   Answer:  117 \n",
      "\u001b[92m☑\u001b[0m Guess:  117 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 146us/step - loss: 0.0027 - acc: 0.9998 - val_loss: 0.0114 - val_acc: 0.9964\n",
      "Question:  852+658 Answer:  1510\n",
      "\u001b[92m☑\u001b[0m Guess:  1510\n",
      "Question:  307+800 Answer:  1107\n",
      "\u001b[92m☑\u001b[0m Guess:  1107\n",
      "Question:  45+492  Answer:  537 \n",
      "\u001b[92m☑\u001b[0m Guess:  537 \n",
      "Question:  85+72   Answer:  157 \n",
      "\u001b[92m☑\u001b[0m Guess:  157 \n",
      "Question:  52+566  Answer:  618 \n",
      "\u001b[92m☑\u001b[0m Guess:  618 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0464 - acc: 0.9847 - val_loss: 0.0857 - val_acc: 0.9705\n",
      "Question:  494+23  Answer:  517 \n",
      "\u001b[92m☑\u001b[0m Guess:  517 \n",
      "Question:  24+651  Answer:  675 \n",
      "\u001b[92m☑\u001b[0m Guess:  675 \n",
      "Question:  171+11  Answer:  182 \n",
      "\u001b[91m☒\u001b[0m Guess:  172 \n",
      "Question:  32+400  Answer:  432 \n",
      "\u001b[92m☑\u001b[0m Guess:  432 \n",
      "Question:  74+753  Answer:  827 \n",
      "\u001b[92m☑\u001b[0m Guess:  827 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0353 - acc: 0.9888 - val_loss: 0.0228 - val_acc: 0.9923\n",
      "Question:  244+52  Answer:  296 \n",
      "\u001b[92m☑\u001b[0m Guess:  296 \n",
      "Question:  816+375 Answer:  1191\n",
      "\u001b[92m☑\u001b[0m Guess:  1191\n",
      "Question:  202+438 Answer:  640 \n",
      "\u001b[92m☑\u001b[0m Guess:  640 \n",
      "Question:  929+276 Answer:  1205\n",
      "\u001b[92m☑\u001b[0m Guess:  1205\n",
      "Question:  45+781  Answer:  826 \n",
      "\u001b[92m☑\u001b[0m Guess:  826 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0041 - acc: 0.9997 - val_loss: 0.0115 - val_acc: 0.9963\n",
      "Question:  21+16   Answer:  37  \n",
      "\u001b[92m☑\u001b[0m Guess:  37  \n",
      "Question:  821+309 Answer:  1130\n",
      "\u001b[92m☑\u001b[0m Guess:  1130\n",
      "Question:  38+20   Answer:  58  \n",
      "\u001b[92m☑\u001b[0m Guess:  58  \n",
      "Question:  360+480 Answer:  840 \n",
      "\u001b[92m☑\u001b[0m Guess:  840 \n",
      "Question:  4+171   Answer:  175 \n",
      "\u001b[92m☑\u001b[0m Guess:  175 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9968\n",
      "Question:  832+295 Answer:  1127\n",
      "\u001b[92m☑\u001b[0m Guess:  1127\n",
      "Question:  290+153 Answer:  443 \n",
      "\u001b[92m☑\u001b[0m Guess:  443 \n",
      "Question:  70+14   Answer:  84  \n",
      "\u001b[92m☑\u001b[0m Guess:  84  \n",
      "Question:  177+245 Answer:  422 \n",
      "\u001b[92m☑\u001b[0m Guess:  422 \n",
      "Question:  31+269  Answer:  300 \n",
      "\u001b[92m☑\u001b[0m Guess:  300 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9968\n",
      "Question:  86+608  Answer:  694 \n",
      "\u001b[92m☑\u001b[0m Guess:  694 \n",
      "Question:  984+22  Answer:  1006\n",
      "\u001b[92m☑\u001b[0m Guess:  1006\n",
      "Question:  786+9   Answer:  795 \n",
      "\u001b[92m☑\u001b[0m Guess:  795 \n",
      "Question:  0+695   Answer:  695 \n",
      "\u001b[92m☑\u001b[0m Guess:  695 \n",
      "Question:  892+0   Answer:  892 \n",
      "\u001b[92m☑\u001b[0m Guess:  892 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 60\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 143us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9972\n",
      "Question:  8+344   Answer:  352 \n",
      "\u001b[92m☑\u001b[0m Guess:  352 \n",
      "Question:  789+724 Answer:  1513\n",
      "\u001b[92m☑\u001b[0m Guess:  1513\n",
      "Question:  755+809 Answer:  1564\n",
      "\u001b[92m☑\u001b[0m Guess:  1564\n",
      "Question:  427+128 Answer:  555 \n",
      "\u001b[92m☑\u001b[0m Guess:  555 \n",
      "Question:  241+837 Answer:  1078\n",
      "\u001b[92m☑\u001b[0m Guess:  1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 61\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 144us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9974\n",
      "Question:  55+5    Answer:  60  \n",
      "\u001b[92m☑\u001b[0m Guess:  60  \n",
      "Question:  990+2   Answer:  992 \n",
      "\u001b[92m☑\u001b[0m Guess:  992 \n",
      "Question:  34+970  Answer:  1004\n",
      "\u001b[92m☑\u001b[0m Guess:  1004\n",
      "Question:  200+27  Answer:  227 \n",
      "\u001b[92m☑\u001b[0m Guess:  227 \n",
      "Question:  852+264 Answer:  1116\n",
      "\u001b[92m☑\u001b[0m Guess:  1116\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 62\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 145us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9974\n",
      "Question:  900+97  Answer:  997 \n",
      "\u001b[92m☑\u001b[0m Guess:  997 \n",
      "Question:  531+70  Answer:  601 \n",
      "\u001b[92m☑\u001b[0m Guess:  601 \n",
      "Question:  844+586 Answer:  1430\n",
      "\u001b[92m☑\u001b[0m Guess:  1430\n",
      "Question:  103+551 Answer:  654 \n",
      "\u001b[92m☑\u001b[0m Guess:  654 \n",
      "Question:  695+440 Answer:  1135\n",
      "\u001b[92m☑\u001b[0m Guess:  1135\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 63\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 144us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9976\n",
      "Question:  329+95  Answer:  424 \n",
      "\u001b[92m☑\u001b[0m Guess:  424 \n",
      "Question:  241+638 Answer:  879 \n",
      "\u001b[92m☑\u001b[0m Guess:  879 \n",
      "Question:  75+215  Answer:  290 \n",
      "\u001b[92m☑\u001b[0m Guess:  290 \n",
      "Question:  536+63  Answer:  599 \n",
      "\u001b[92m☑\u001b[0m Guess:  599 \n",
      "Question:  613+1   Answer:  614 \n",
      "\u001b[92m☑\u001b[0m Guess:  614 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 64\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9965\n",
      "Question:  936+477 Answer:  1413\n",
      "\u001b[92m☑\u001b[0m Guess:  1413\n",
      "Question:  896+325 Answer:  1221\n",
      "\u001b[92m☑\u001b[0m Guess:  1221\n",
      "Question:  739+45  Answer:  784 \n",
      "\u001b[92m☑\u001b[0m Guess:  784 \n",
      "Question:  938+813 Answer:  1751\n",
      "\u001b[92m☑\u001b[0m Guess:  1751\n",
      "Question:  541+283 Answer:  824 \n",
      "\u001b[92m☑\u001b[0m Guess:  824 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 65\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 6s 141us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9965\n",
      "Question:  642+422 Answer:  1064\n",
      "\u001b[92m☑\u001b[0m Guess:  1064\n",
      "Question:  26+978  Answer:  1004\n",
      "\u001b[92m☑\u001b[0m Guess:  1004\n",
      "Question:  173+58  Answer:  231 \n",
      "\u001b[92m☑\u001b[0m Guess:  231 \n",
      "Question:  50+481  Answer:  531 \n",
      "\u001b[92m☑\u001b[0m Guess:  531 \n",
      "Question:  63+504  Answer:  567 \n",
      "\u001b[92m☑\u001b[0m Guess:  567 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 66\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      " 9984/45000 [=====>........................] - ETA: 4s - loss: 0.0019 - acc: 0.9999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-0139eb10c780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train(model3char, x_train_3char, y_train_3char, x_val_3char, y_val_3char,  n_epochs=100, \n\u001b[0;32m----> 2\u001b[0;31m       BATCH_SIZE=128, REVERSE=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-92adf2927e8a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, x_train, y_train, x_val, y_val, n_epochs, BATCH_SIZE, REVERSE)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Select 5 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model3char, x_train_3char, y_train_3char, x_val_3char, y_val_3char,  n_epochs=100, \n",
    "      BATCH_SIZE=128, REVERSE=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-CAckXJwJKM"
   },
   "source": [
    "Check Five digits reversed:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHhfokYHwJKN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de 13_RNN_learning_to_add_as_transaltion_student-version.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
