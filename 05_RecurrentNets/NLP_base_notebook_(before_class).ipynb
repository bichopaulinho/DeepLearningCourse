{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_DenEigZXln"
   },
   "source": [
    "# Processing natural language with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q124IgXxaTdV",
    "outputId": "00b36a0d-30b8-47c5-d087-a581f979f65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUmGc53waUkw"
   },
   "outputs": [],
   "source": [
    "def plot_metric(history, metric):\n",
    "    history_dict = history.history\n",
    "    values = history_dict[metric]\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        val_values = history_dict['val_' + metric]\n",
    "\n",
    "    epochs = range(1, len(values) + 1)\n",
    "\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        plt.plot(epochs, val_values, label='Validation')\n",
    "    plt.semilogy(epochs, values, label='Training')\n",
    "\n",
    "    if 'val_' + metric in history_dict.keys():  \n",
    "        plt.title('Training and validation %s' % metric)\n",
    "    else:\n",
    "        plt.title('Training %s' % metric)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSIPD2c3aVe8"
   },
   "source": [
    "## Data downloads\n",
    "\n",
    "Sentiment Analysis\n",
    "\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "Download embeddings data (**not necessary for all the exercises**).\n",
    "\n",
    "Several research groups and companies share embeddings for natural languages, that have been obtained by different methods over large corpuses of text. Here we will use one of these datasets of embeddings for the English language, and will evaluate if these embeddings improve our model.\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "-JMOXg7AcfPn",
    "outputId": "a708006a-a96c-450d-a8c5-9a5bf44dd47a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:03:00 --:--:--     0\n",
      "curl: (56) Recv failure: Connection was reset\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  822M  100  822M    0     0  1279k      0  0:10:58  0:10:58 --:--:-- 1012k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [ ! -d data/aclImdb/ ]; then\n",
    "  curl http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz > aclImdb_v1.tar.gz\n",
    "fi\n",
    "\n",
    "# Only for some exercises\n",
    "if [ ! -f data/glove/glove.6B.100d.txt ]; then\n",
    "   curl https://nlp.stanford.edu/data/glove.6B.zip > glove.6B.zip \n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "paM99cA1fKKO",
    "outputId": "92f28513-3155-4fb8-f54e-f832b8b6854d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 903M\n",
      "-rw-r--r-- 1 root root  81M Jan  9 16:41 aclImdb_v1.tar.gz\n",
      "-rw-r--r-- 1 root root 823M Jan  9 16:42 glove.6B.zip\n",
      "drwxr-xr-x 1 root root 4.0K Jan  8 17:15 sample_data\n"
     ]
    }
   ],
   "source": [
    "# Check that the downloads look ok\n",
    "!ls -hl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZcKYJcldw2Z"
   },
   "source": [
    "### Data uncompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t7UBOm4cabU-",
    "outputId": "d347c160-1824-4c28-84e8-5213211d5e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping. IMDB data already uncompressed.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [ ! -d data/aclImdb/ ]; then\n",
    "  mkdir -p data\n",
    "  mv aclImdb_v1.tar.gz data/\n",
    "  cd data && tar zxf aclImdb_v1.tar.gz && rm aclImdb_v1.tar.gz\n",
    "else\n",
    "  echo \"Skipping. IMDB data already uncompressed.\"\n",
    " fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3M3-4Otzaj3y",
    "outputId": "27790599-1bba-4da9-b56f-d59fb4e7356e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping. Glove embeddings already uncompressed.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Only for some exercises\n",
    "if [ ! -f data/glove/glove.6B.100d.txt ]; then\n",
    "  mkdir -p data/glove && cd data/glove && unzip ../../glove.6B.zip && rm ../../glove.6B.zip\n",
    "  head data/glove/glove.6B.100d.txt\n",
    "else\n",
    "  echo \"Skipping. Glove embeddings already uncompressed.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFxlwDZxazJ2"
   },
   "source": [
    "# Data preparation for the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Rqwbsr3a65H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hjQhDsUa7SM"
   },
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvCu-FFnbzmT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5CrLHyCa_OI"
   },
   "outputs": [],
   "source": [
    "def keras2tpu(m):\n",
    "  tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
    "    m,\n",
    "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
    "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])))\n",
    "\n",
    "  return tpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8imsMPeda94V"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2HfKd0SbAu8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vutyKWPAbCFt"
   },
   "source": [
    "# Quick evaluation of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_cUOdpSbELC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m069P-fFbEeB"
   },
   "source": [
    "# Detailed evaluation of text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65XNedWsbIW9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP base notebook (before class).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
